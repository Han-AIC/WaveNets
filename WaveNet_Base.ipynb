{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 823
    },
    "colab_type": "code",
    "id": "8SvwaLS8gA8M",
    "outputId": "dc3ff2bf-c420-4836-9894-421f5ac3e324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Sys Info ---------\n",
      "3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      " \n",
      "--------- Utility Info ---------\n",
      "Cpu Usage: 7.5%\n",
      "Memory Usage:\n",
      "svmem(total=16964157440, available=7722008576, percent=54.5, used=9242148864, free=7722008576)\n",
      " \n",
      "--------- Package Versions ---------\n",
      "Tensorflow Version: 2.0.0\n",
      "Numpy Version: 1.17.4\n",
      "Pandas Version: 0.25.3\n",
      "Matplotlib Version: 3.1.3\n",
      " \n",
      "--------- Local Hardware ---------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8425972350462598668, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 4937233203\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2302254523380862789\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "from glob import glob\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime \n",
    "import pydot \n",
    "# import graphviz\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sb\n",
    "import psutil\n",
    "\n",
    "# Directly importing from tf.keras for convenience\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Flatten, Dropout, MaxPool1D, AveragePooling1D, MaxPool2D,GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling2D, concatenate, Activation, Dropout, Lambda, Multiply, Add\n",
    "\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"--------- Sys Info ---------\")\n",
    "print(sys.version)\n",
    "print(\" \")\n",
    "print(\"--------- Utility Info ---------\")\n",
    "print(\"Cpu Usage: \" + str(psutil.cpu_percent()) + \"%\")\n",
    "print(\"Memory Usage:\")\n",
    "print(psutil.virtual_memory())\n",
    "print(\" \")\n",
    "print(\"--------- Package Versions ---------\")\n",
    "print(\"Tensorflow Version: \" + tf.__version__)\n",
    "print(\"Numpy Version: \" + np.__version__)\n",
    "print(\"Pandas Version: \" + pd.__version__)\n",
    "print(\"Matplotlib Version: \" + mpl.__version__)\n",
    "print(\" \")\n",
    "print(\"--------- Local Hardware ---------\")\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveNet\n",
    "\n",
    "The goal here is to produce a generative model which can be used for prediction of time series data. The model below represents an implementation of a Convolutional WaveNetwork by Van den Oord et al. This current model is a testing/developmental prototype, and requires a 1-d input array of scalar values. Hence, it is set up only for single dimensional time-series data. With a small amount of work, it can be made ready for an input array of high dimensional vectors, such as words or audio waveforms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./diagrams/Architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./diagrams/residual_block.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convolutional Wavenet Model\n",
    "\n",
    "'''\n",
    "\n",
    "class WaveNet:\n",
    "    def __init__(self,\n",
    "                dilation_size,  \n",
    "                dilation_stages,\n",
    "                input_dim,\n",
    "                num_hidden_kernels,\n",
    "                hidden_kernel_size,\n",
    "                num_output_kernels,\n",
    "                output_kernel_size,\n",
    "                output_dim,\n",
    "                activation_function,\n",
    "                output_activation,\n",
    "                callbacks, \n",
    "                learning_rate, \n",
    "                momentum, \n",
    "                cost_function, \n",
    "                metrics, \n",
    "                optim):\n",
    "        \n",
    "        self.dilation_size = dilation_size\n",
    "        self.lookback_length = dilation_size**dilation_stages\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "        self.num_hidden_kernels = num_hidden_kernels\n",
    "        self.hidden_kernel_size = hidden_kernel_size\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "        self.num_output_kernels = num_output_kernels\n",
    "        self.output_kernel_size = output_kernel_size\n",
    "        self.output_activation = output_activation\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.callbacks = callbacks \n",
    "        self.learning_rate = learning_rate \n",
    "        self.momentum = momentum \n",
    "        self.cost_function = cost_function\n",
    "        self.metrics = metrics\n",
    "        self.optim = optim\n",
    "        \n",
    "        self.model = None\n",
    "        self.model_history = None\n",
    "            \n",
    "    def __prepare_input_layers(self):\n",
    "      output = []\n",
    "      for i in range(int(self.lookback_length)):\n",
    "        output.append(Input(shape=(None, self.input_dim)))\n",
    "      return output\n",
    "\n",
    "    def __concatenate_previous_layers(self, layers, i, j):\n",
    "        concat_layers = []\n",
    "        for k in range(self.dilation_size):\n",
    "            concat_layers.append(layers[i][j*self.dilation_size + k])\n",
    "        return concatenate(concat_layers)\n",
    "\n",
    "    def __define_model(self):\n",
    "        \n",
    "        dilation_stages = (np.log(self.lookback_length) / np.log(self.dilation_size)).astype('int64')\n",
    "\n",
    "        layers = [self.__prepare_input_layers()]\n",
    "        skip_connections = []\n",
    "        \n",
    "        for i in range(dilation_stages):\n",
    "          layer_arr = []\n",
    "          for j in range(int(self.lookback_length / self.dilation_size**(i+1))):          \n",
    "            if (i >= 0) and (i < (dilation_stages - 1)):\n",
    "                \n",
    "              x = self.__concatenate_previous_layers(layers, i, j)\n",
    "            \n",
    "              x = Conv1D(self.num_hidden_kernels, self.hidden_kernel_size, padding='same', activation=self.activation_function)(x) \n",
    "              x_filter = Conv1D(self.num_hidden_kernels, self.hidden_kernel_size, padding='same')(x) \n",
    "              x_gate = Conv1D(self.num_hidden_kernels, self.hidden_kernel_size, padding='same')(x)\n",
    "              z = Multiply()([Activation('tanh')(x_filter), Activation('sigmoid')(x_gate)])\n",
    "              z = Conv1D(self.num_hidden_kernels, self.hidden_kernel_size, padding='same', activation=self.activation_function)(z) \n",
    "              skip_connections.append(z)   \n",
    "              x = Add()([x, z])\n",
    "              layer_arr.append(x)\n",
    "            \n",
    "            else:\n",
    "              output = Add()(skip_connections)\n",
    "              output = Activation(self.activation_function)(output)\n",
    "              output = Conv1D(self.num_output_kernels, self.output_kernel_size, padding='same', activation=self.activation_function)(output) \n",
    "              output = Dense(self.output_dim, activation=output_activation)(output)\n",
    "              layer_arr.append(output)\n",
    "            \n",
    "          layers.append(layer_arr)\n",
    "\n",
    "        self.model = Model(layers[0], \n",
    "                           layers[-1])\n",
    "    \n",
    "    def __compile_model(self, nesterov=True):\n",
    "\n",
    "        self.model.compile(optimizer=optim(learning_rate=self.learning_rate, \n",
    "                                      momentum=self.momentum, \n",
    "                                      nesterov=nesterov), \n",
    "                      loss=self.cost_function, \n",
    "                      metrics=self.metrics)\n",
    "\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.__define_model()\n",
    "        self.__compile_model()\n",
    "        \n",
    "    def return_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def __sequence_data_window(self, arr, start):\n",
    "        end = start + self.lookback_length\n",
    "\n",
    "        if ((end - start) % self.dilation_size != 0 or (end - start) < 0):\n",
    "            raise Exception('Need window size which is a factor of dilation')\n",
    "\n",
    "        output = [np.array([arr[i]]).reshape(1, 1,-1) for i in range(start, end)]\n",
    "        return output\n",
    "    \n",
    "    def __sequence_data_window_multi_dim(self, arr, start):\n",
    "        end = start + self.lookback_length\n",
    "\n",
    "        if ((end - start) % self.dilation_size != 0 or (end - start) < 0):\n",
    "            raise Exception('Need window size which is a factor of dilation')\n",
    "\n",
    "        X = [np.array([arr[i, 0:-1]]).reshape(1, 1,-1) for i in range(start, end)]\n",
    "        y = [np.array([arr[i, -1]]).reshape(1, 1,-1) for i in range(start, end)]\n",
    "        return X, y\n",
    "\n",
    "    def train_model(self, data):\n",
    "        model_History = None\n",
    "\n",
    "        for epoch in range(1):\n",
    "            for i in range(0, len(data)-(self.lookback_length)):\n",
    "\n",
    "                if(len(data)<self.lookback_length):\n",
    "                    raise Exception('Window Size must be lower than sequence length.')\n",
    "\n",
    "                \n",
    "                train_sequence = self.__sequence_data_window(data, i)\n",
    "\n",
    "                print('-----------------------------')\n",
    "                print(train_sequence)\n",
    "                print(i)\n",
    "                print(i+self.lookback_length)\n",
    "                print(np.array([data[i+self.lookback_length]]))\n",
    "\n",
    "                self.model_history = self.model.fit(train_sequence, np.array([data[i+self.lookback_length]]), epochs=1, batch_size = 1, callbacks=self.callbacks, verbose=True)\n",
    "\n",
    "                print(self.model.predict(train_sequence))\n",
    "                \n",
    "                    \n",
    "            \n",
    "    def predict(self, data, time_steps):\n",
    "        \n",
    "        pred_data = data \n",
    "        while len(pred_data) < self.lookback_length:\n",
    "            new_arr = [data[0]]\n",
    "            new_arr += pred_data\n",
    "            pred_data = new_arr\n",
    "            \n",
    "\n",
    "        for i in range(time_steps):\n",
    "            current_pred_data = self.__sequence_data_window(pred_data, i)\n",
    "            print(current_pred_data)\n",
    "            prediction = self.model.predict(current_pred_data)\n",
    "            pred_data.append(prediction)\n",
    "            \n",
    "            print(prediction)\n",
    "            print(type(prediction))\n",
    "            \n",
    "def create_training_sequence(d):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    sample = []\n",
    "\n",
    "    power = np.random.normal(1, 1, 1)[0]\n",
    "    base1 = np.random.normal(1, 0.5, 1)[0]\n",
    "    base2 = 0\n",
    "    for j in range(1, d+1):\n",
    "      base1 += (j*2)\n",
    "      base2 += base1**(power**2)\n",
    "      sample.append(base1 + base2)\n",
    "\n",
    "    sample = np.array(sample)\n",
    "    sample -= np.mean(sample)\n",
    "    sample /= np.std(sample)\n",
    "    return np.array(sample)\n",
    "\n",
    "def create_training_sequence_labeled_vector(d):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    sample = []\n",
    "\n",
    "    power = np.random.normal(1, 1, 1)[0]\n",
    "    base1 = np.random.normal(1, 0.5, 1)[0]\n",
    "    base2 = 0\n",
    "    for j in range(1, d+1):\n",
    "      base1 += (j*2)\n",
    "      base2 += base1**(power**2)\n",
    "      sample.append([power*j, base1**2, base2**0.5, base1 + base2])\n",
    "\n",
    "    sample = np.array(sample)\n",
    "    sample -= np.mean(sample)\n",
    "    sample /= np.std(sample)\n",
    "    return np.array(sample)\n",
    "\n",
    "\n",
    "dilation_size = 2\n",
    "dilation_stages = 3\n",
    "\n",
    "input_dim = 4\n",
    "num_hidden_kernels = 16\n",
    "hidden_kernel_size = 1\n",
    "num_output_kernels = 32\n",
    "output_kernel_size = 1\n",
    "output_dim = 4\n",
    "activation_function = 'relu'\n",
    "output_activation = 'linear'\n",
    "\n",
    "\n",
    "earlyStoppingCallback = EarlyStopping(monitor='loss', patience=3)\n",
    "callbacks = [earlyStoppingCallback]\n",
    "\n",
    "learning_rate = 0.05\n",
    "momentum = 0.6 \n",
    "\n",
    "cost_function = 'MSE'\n",
    "metrics = ['mse']\n",
    "optim = SGD\n",
    "\n",
    "wavenet = WaveNet(dilation_size,\n",
    "                dilation_stages,\n",
    "                input_dim,\n",
    "                num_hidden_kernels,\n",
    "                hidden_kernel_size,\n",
    "                num_output_kernels,\n",
    "                output_kernel_size,\n",
    "                output_dim,\n",
    "                activation_function,\n",
    "                output_activation,\n",
    "                callbacks, \n",
    "                learning_rate, \n",
    "                momentum, \n",
    "                cost_function, \n",
    "                metrics, \n",
    "                optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenet.build_model()\n",
    "\n",
    "# plot_model(wavenet.return_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavenet.return_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_training_sequence_labeled_vector(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "[array([[[-0.316473  , -0.31647281, -0.31647298, -0.31647289]]]), array([[[-0.31647298, -0.31647189, -0.31647295, -0.31647266]]]), array([[[-0.31647296, -0.31646915, -0.31647292, -0.31647228]]]), array([[[-0.31647293, -0.31646296, -0.31647289, -0.31647173]]]), array([[[-0.31647291, -0.31645115, -0.31647285, -0.31647097]]]), array([[[-0.31647289, -0.316431  , -0.31647281, -0.31646997]]]), array([[[-0.31647287, -0.31639926, -0.31647276, -0.31646872]]]), array([[[-0.31647285, -0.31635211, -0.31647271, -0.31646719]]])]\n",
      "0\n",
      "8\n",
      "[[-0.31647283 -0.31628522 -0.31647267 -0.31646534]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 0.0910 - mse: 0.0910\n",
      "[[[-0.20482183 -0.09976186 -0.01715525  0.05658501]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647298, -0.31647189, -0.31647295, -0.31647266]]]), array([[[-0.31647296, -0.31646915, -0.31647292, -0.31647228]]]), array([[[-0.31647293, -0.31646296, -0.31647289, -0.31647173]]]), array([[[-0.31647291, -0.31645115, -0.31647285, -0.31647097]]]), array([[[-0.31647289, -0.316431  , -0.31647281, -0.31646997]]]), array([[[-0.31647287, -0.31639926, -0.31647276, -0.31646872]]]), array([[[-0.31647285, -0.31635211, -0.31647271, -0.31646719]]]), array([[[-0.31647283, -0.31628522, -0.31647267, -0.31646534]]])]\n",
      "1\n",
      "9\n",
      "[[-0.3164728  -0.31619369 -0.31647261 -0.31646316]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0720 - mse: 0.0720\n",
      "[[[-0.22822726 -0.13139123 -0.05074639  0.0105769 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647296, -0.31646915, -0.31647292, -0.31647228]]]), array([[[-0.31647293, -0.31646296, -0.31647289, -0.31647173]]]), array([[[-0.31647291, -0.31645115, -0.31647285, -0.31647097]]]), array([[[-0.31647289, -0.316431  , -0.31647281, -0.31646997]]]), array([[[-0.31647287, -0.31639926, -0.31647276, -0.31646872]]]), array([[[-0.31647285, -0.31635211, -0.31647271, -0.31646719]]]), array([[[-0.31647283, -0.31628522, -0.31647267, -0.31646534]]]), array([[[-0.3164728 , -0.31619369, -0.31647261, -0.31646316]]])]\n",
      "2\n",
      "10\n",
      "[[-0.31647278 -0.31607209 -0.31647256 -0.31646063]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0549 - mse: 0.0549\n",
      "[[[-0.24460667 -0.15610054 -0.08928932 -0.02969545]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647293, -0.31646296, -0.31647289, -0.31647173]]]), array([[[-0.31647291, -0.31645115, -0.31647285, -0.31647097]]]), array([[[-0.31647289, -0.316431  , -0.31647281, -0.31646997]]]), array([[[-0.31647287, -0.31639926, -0.31647276, -0.31646872]]]), array([[[-0.31647285, -0.31635211, -0.31647271, -0.31646719]]]), array([[[-0.31647283, -0.31628522, -0.31647267, -0.31646534]]]), array([[[-0.3164728 , -0.31619369, -0.31647261, -0.31646316]]]), array([[[-0.31647278, -0.31607209, -0.31647256, -0.31646063]]])]\n",
      "3\n",
      "11\n",
      "[[-0.31647276 -0.31591445 -0.31647251 -0.31645771]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0411 - mse: 0.0411\n",
      "[[[-0.2705182  -0.1819227  -0.12294565 -0.05984043]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647291, -0.31645115, -0.31647285, -0.31647097]]]), array([[[-0.31647289, -0.316431  , -0.31647281, -0.31646997]]]), array([[[-0.31647287, -0.31639926, -0.31647276, -0.31646872]]]), array([[[-0.31647285, -0.31635211, -0.31647271, -0.31646719]]]), array([[[-0.31647283, -0.31628522, -0.31647267, -0.31646534]]]), array([[[-0.3164728 , -0.31619369, -0.31647261, -0.31646316]]]), array([[[-0.31647278, -0.31607209, -0.31647256, -0.31646063]]]), array([[[-0.31647276, -0.31591445, -0.31647251, -0.31645771]]])]\n",
      "4\n",
      "12\n",
      "[[-0.31647274 -0.31571424 -0.31647245 -0.31645439]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0308 - mse: 0.0308\n",
      "[[[-0.29336306 -0.20509562 -0.15368073 -0.0887837 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647289, -0.316431  , -0.31647281, -0.31646997]]]), array([[[-0.31647287, -0.31639926, -0.31647276, -0.31646872]]]), array([[[-0.31647285, -0.31635211, -0.31647271, -0.31646719]]]), array([[[-0.31647283, -0.31628522, -0.31647267, -0.31646534]]]), array([[[-0.3164728 , -0.31619369, -0.31647261, -0.31646316]]]), array([[[-0.31647278, -0.31607209, -0.31647256, -0.31646063]]]), array([[[-0.31647276, -0.31591445, -0.31647251, -0.31645771]]]), array([[[-0.31647274, -0.31571424, -0.31647245, -0.31645439]]])]\n",
      "5\n",
      "13\n",
      "[[-0.31647272 -0.3154644  -0.31647239 -0.31645065]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0228 - mse: 0.0228\n",
      "[[[-0.31455585 -0.22762647 -0.1793167  -0.11509518]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647287, -0.31639926, -0.31647276, -0.31646872]]]), array([[[-0.31647285, -0.31635211, -0.31647271, -0.31646719]]]), array([[[-0.31647283, -0.31628522, -0.31647267, -0.31646534]]]), array([[[-0.3164728 , -0.31619369, -0.31647261, -0.31646316]]]), array([[[-0.31647278, -0.31607209, -0.31647256, -0.31646063]]]), array([[[-0.31647276, -0.31591445, -0.31647251, -0.31645771]]]), array([[[-0.31647274, -0.31571424, -0.31647245, -0.31645439]]]), array([[[-0.31647272, -0.3154644 , -0.31647239, -0.31645065]]])]\n",
      "6\n",
      "14\n",
      "[[-0.3164727  -0.31515734 -0.31647233 -0.31644645]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0168 - mse: 0.0168\n",
      "[[[-0.32960773 -0.24620566 -0.20150596 -0.13977805]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647285, -0.31635211, -0.31647271, -0.31646719]]]), array([[[-0.31647283, -0.31628522, -0.31647267, -0.31646534]]]), array([[[-0.3164728 , -0.31619369, -0.31647261, -0.31646316]]]), array([[[-0.31647278, -0.31607209, -0.31647256, -0.31646063]]]), array([[[-0.31647276, -0.31591445, -0.31647251, -0.31645771]]]), array([[[-0.31647274, -0.31571424, -0.31647245, -0.31645439]]]), array([[[-0.31647272, -0.3154644 , -0.31647239, -0.31645065]]]), array([[[-0.3164727 , -0.31515734, -0.31647233, -0.31644645]]])]\n",
      "7\n",
      "15\n",
      "[[-0.31647267 -0.31478489 -0.31647227 -0.31644178]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0123 - mse: 0.0123\n",
      "[[[-0.33882415 -0.2611134  -0.22049883 -0.16248257]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647283, -0.31628522, -0.31647267, -0.31646534]]]), array([[[-0.3164728 , -0.31619369, -0.31647261, -0.31646316]]]), array([[[-0.31647278, -0.31607209, -0.31647256, -0.31646063]]]), array([[[-0.31647276, -0.31591445, -0.31647251, -0.31645771]]]), array([[[-0.31647274, -0.31571424, -0.31647245, -0.31645439]]]), array([[[-0.31647272, -0.3154644 , -0.31647239, -0.31645065]]]), array([[[-0.3164727 , -0.31515734, -0.31647233, -0.31644645]]]), array([[[-0.31647267, -0.31478489, -0.31647227, -0.31644178]]])]\n",
      "8\n",
      "16\n",
      "[[-0.31647265 -0.31433836 -0.31647221 -0.31643661]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0091 - mse: 0.0091\n",
      "[[[-0.34201404 -0.27679798 -0.23348013 -0.18366008]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164728 , -0.31619369, -0.31647261, -0.31646316]]]), array([[[-0.31647278, -0.31607209, -0.31647256, -0.31646063]]]), array([[[-0.31647276, -0.31591445, -0.31647251, -0.31645771]]]), array([[[-0.31647274, -0.31571424, -0.31647245, -0.31645439]]]), array([[[-0.31647272, -0.3154644 , -0.31647239, -0.31645065]]]), array([[[-0.3164727 , -0.31515734, -0.31647233, -0.31644645]]]), array([[[-0.31647267, -0.31478489, -0.31647227, -0.31644178]]]), array([[[-0.31647265, -0.31433836, -0.31647221, -0.31643661]]])]\n",
      "9\n",
      "17\n",
      "[[-0.31647263 -0.31380852 -0.31647214 -0.31643093]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 0.0066 - mse: 0.0066\n",
      "[[[-0.3421954  -0.28851497 -0.24455857 -0.20242216]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647278, -0.31607209, -0.31647256, -0.31646063]]]), array([[[-0.31647276, -0.31591445, -0.31647251, -0.31645771]]]), array([[[-0.31647274, -0.31571424, -0.31647245, -0.31645439]]]), array([[[-0.31647272, -0.3154644 , -0.31647239, -0.31645065]]]), array([[[-0.3164727 , -0.31515734, -0.31647233, -0.31644645]]]), array([[[-0.31647267, -0.31478489, -0.31647227, -0.31644178]]]), array([[[-0.31647265, -0.31433836, -0.31647221, -0.31643661]]]), array([[[-0.31647263, -0.31380852, -0.31647214, -0.31643093]]])]\n",
      "10\n",
      "18\n",
      "[[-0.31647261 -0.3131856  -0.31647207 -0.31642471]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0049 - mse: 0.0049\n",
      "[[[-0.33844104 -0.29683533 -0.25324148 -0.2193171 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647276, -0.31591445, -0.31647251, -0.31645771]]]), array([[[-0.31647274, -0.31571424, -0.31647245, -0.31645439]]]), array([[[-0.31647272, -0.3154644 , -0.31647239, -0.31645065]]]), array([[[-0.3164727 , -0.31515734, -0.31647233, -0.31644645]]]), array([[[-0.31647267, -0.31478489, -0.31647227, -0.31644178]]]), array([[[-0.31647265, -0.31433836, -0.31647221, -0.31643661]]]), array([[[-0.31647263, -0.31380852, -0.31647214, -0.31643093]]]), array([[[-0.31647261, -0.3131856 , -0.31647207, -0.31642471]]])]\n",
      "11\n",
      "19\n",
      "[[-0.31647259 -0.31245926 -0.31647201 -0.31641792]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0035 - mse: 0.0035\n",
      "[[[-0.33543402 -0.30295065 -0.26152042 -0.23383985]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647274, -0.31571424, -0.31647245, -0.31645439]]]), array([[[-0.31647272, -0.3154644 , -0.31647239, -0.31645065]]]), array([[[-0.3164727 , -0.31515734, -0.31647233, -0.31644645]]]), array([[[-0.31647267, -0.31478489, -0.31647227, -0.31644178]]]), array([[[-0.31647265, -0.31433836, -0.31647221, -0.31643661]]]), array([[[-0.31647263, -0.31380852, -0.31647214, -0.31643093]]]), array([[[-0.31647261, -0.3131856 , -0.31647207, -0.31642471]]]), array([[[-0.31647259, -0.31245926, -0.31647201, -0.31641792]]])]\n",
      "12\n",
      "20\n",
      "[[-0.31647257 -0.31161865 -0.31647194 -0.31641056]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0026 - mse: 0.0026\n",
      "[[[-0.3322024  -0.30717283 -0.26891932 -0.2463179 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647272, -0.3154644 , -0.31647239, -0.31645065]]]), array([[[-0.3164727 , -0.31515734, -0.31647233, -0.31644645]]]), array([[[-0.31647267, -0.31478489, -0.31647227, -0.31644178]]]), array([[[-0.31647265, -0.31433836, -0.31647221, -0.31643661]]]), array([[[-0.31647263, -0.31380852, -0.31647214, -0.31643093]]]), array([[[-0.31647261, -0.3131856 , -0.31647207, -0.31642471]]]), array([[[-0.31647259, -0.31245926, -0.31647201, -0.31641792]]]), array([[[-0.31647257, -0.31161865, -0.31647194, -0.31641056]]])]\n",
      "13\n",
      "21\n",
      "[[-0.31647254 -0.31065235 -0.31647187 -0.31640259]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "[[[-0.32900965 -0.30991435 -0.27550754 -0.25693464]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164727 , -0.31515734, -0.31647233, -0.31644645]]]), array([[[-0.31647267, -0.31478489, -0.31647227, -0.31644178]]]), array([[[-0.31647265, -0.31433836, -0.31647221, -0.31643661]]]), array([[[-0.31647263, -0.31380852, -0.31647214, -0.31643093]]]), array([[[-0.31647261, -0.3131856 , -0.31647207, -0.31642471]]]), array([[[-0.31647259, -0.31245926, -0.31647201, -0.31641792]]]), array([[[-0.31647257, -0.31161865, -0.31647194, -0.31641056]]]), array([[[-0.31647254, -0.31065235, -0.31647187, -0.31640259]]])]\n",
      "14\n",
      "22\n",
      "[[-0.31647252 -0.30954841 -0.31647179 -0.316394  ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0013 - mse: 0.0013\n",
      "[[[-0.32607934 -0.3115514  -0.28135514 -0.26592216]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647267, -0.31478489, -0.31647227, -0.31644178]]]), array([[[-0.31647265, -0.31433836, -0.31647221, -0.31643661]]]), array([[[-0.31647263, -0.31380852, -0.31647214, -0.31643093]]]), array([[[-0.31647261, -0.3131856 , -0.31647207, -0.31642471]]]), array([[[-0.31647259, -0.31245926, -0.31647201, -0.31641792]]]), array([[[-0.31647257, -0.31161865, -0.31647194, -0.31641056]]]), array([[[-0.31647254, -0.31065235, -0.31647187, -0.31640259]]]), array([[[-0.31647252, -0.30954841, -0.31647179, -0.316394  ]]])]\n",
      "15\n",
      "23\n",
      "[[-0.3164725  -0.30829433 -0.31647172 -0.31638475]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 9.7215e-04 - mse: 9.7215e-04\n",
      "[[[-0.32352307 -0.31235215 -0.2865178  -0.27351245]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647265, -0.31433836, -0.31647221, -0.31643661]]]), array([[[-0.31647263, -0.31380852, -0.31647214, -0.31643093]]]), array([[[-0.31647261, -0.3131856 , -0.31647207, -0.31642471]]]), array([[[-0.31647259, -0.31245926, -0.31647201, -0.31641792]]]), array([[[-0.31647257, -0.31161865, -0.31647194, -0.31641056]]]), array([[[-0.31647254, -0.31065235, -0.31647187, -0.31640259]]]), array([[[-0.31647252, -0.30954841, -0.31647179, -0.316394  ]]]), array([[[-0.3164725 , -0.30829433, -0.31647172, -0.31638475]]])]\n",
      "16\n",
      "24\n",
      "[[-0.31647248 -0.30687709 -0.31647165 -0.31637485]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 7.0496e-04 - mse: 7.0496e-04\n",
      "[[[-0.32137084 -0.3125131  -0.29104525 -0.27990597]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647263, -0.31380852, -0.31647214, -0.31643093]]]), array([[[-0.31647261, -0.3131856 , -0.31647207, -0.31642471]]]), array([[[-0.31647259, -0.31245926, -0.31647201, -0.31641792]]]), array([[[-0.31647257, -0.31161865, -0.31647194, -0.31641056]]]), array([[[-0.31647254, -0.31065235, -0.31647187, -0.31640259]]]), array([[[-0.31647252, -0.30954841, -0.31647179, -0.316394  ]]]), array([[[-0.3164725 , -0.30829433, -0.31647172, -0.31638475]]]), array([[[-0.31647248, -0.30687709, -0.31647165, -0.31637485]]])]\n",
      "17\n",
      "25\n",
      "[[-0.31647246 -0.30528309 -0.31647157 -0.31636425]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 5.1435e-04 - mse: 5.1435e-04\n",
      "[[[-0.31960678 -0.3121745  -0.29498813 -0.2852799 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647261, -0.3131856 , -0.31647207, -0.31642471]]]), array([[[-0.31647259, -0.31245926, -0.31647201, -0.31641792]]]), array([[[-0.31647257, -0.31161865, -0.31647194, -0.31641056]]]), array([[[-0.31647254, -0.31065235, -0.31647187, -0.31640259]]]), array([[[-0.31647252, -0.30954841, -0.31647179, -0.316394  ]]]), array([[[-0.3164725 , -0.30829433, -0.31647172, -0.31638475]]]), array([[[-0.31647248, -0.30687709, -0.31647165, -0.31637485]]]), array([[[-0.31647246, -0.30528309, -0.31647157, -0.31636425]]])]\n",
      "18\n",
      "26\n",
      "[[-0.31647244 -0.30349821 -0.3164715  -0.31635295]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 3.7932e-04 - mse: 3.7932e-04\n",
      "[[[-0.3181886  -0.31143326 -0.29839838 -0.2897873 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647259, -0.31245926, -0.31647201, -0.31641792]]]), array([[[-0.31647257, -0.31161865, -0.31647194, -0.31641056]]]), array([[[-0.31647254, -0.31065235, -0.31647187, -0.31640259]]]), array([[[-0.31647252, -0.30954841, -0.31647179, -0.316394  ]]]), array([[[-0.3164725 , -0.30829433, -0.31647172, -0.31638475]]]), array([[[-0.31647248, -0.30687709, -0.31647165, -0.31637485]]]), array([[[-0.31647246, -0.30528309, -0.31647157, -0.31636425]]]), array([[[-0.31647244, -0.30349821, -0.3164715 , -0.31635295]]])]\n",
      "19\n",
      "27\n",
      "[[-0.31647241 -0.30150778 -0.31647142 -0.31634091]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 2.8449e-04 - mse: 2.8449e-04\n",
      "[[[-0.31707343 -0.3103545  -0.3013296  -0.2935555 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647257, -0.31161865, -0.31647194, -0.31641056]]]), array([[[-0.31647254, -0.31065235, -0.31647187, -0.31640259]]]), array([[[-0.31647252, -0.30954841, -0.31647179, -0.316394  ]]]), array([[[-0.3164725 , -0.30829433, -0.31647172, -0.31638475]]]), array([[[-0.31647248, -0.30687709, -0.31647165, -0.31637485]]]), array([[[-0.31647246, -0.30528309, -0.31647157, -0.31636425]]]), array([[[-0.31647244, -0.30349821, -0.3164715 , -0.31635295]]]), array([[[-0.31647241, -0.30150778, -0.31647142, -0.31634091]]])]\n",
      "20\n",
      "28\n",
      "[[-0.31647239 -0.29929659 -0.31647134 -0.31632813]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.1870e-04 - mse: 2.1870e-04\n",
      "[[[-0.31616104 -0.30898088 -0.30383205 -0.29670745]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647254, -0.31065235, -0.31647187, -0.31640259]]]), array([[[-0.31647252, -0.30954841, -0.31647179, -0.316394  ]]]), array([[[-0.3164725 , -0.30829433, -0.31647172, -0.31638475]]]), array([[[-0.31647248, -0.30687709, -0.31647165, -0.31637485]]]), array([[[-0.31647246, -0.30528309, -0.31647157, -0.31636425]]]), array([[[-0.31647244, -0.30349821, -0.3164715 , -0.31635295]]]), array([[[-0.31647241, -0.30150778, -0.31647142, -0.31634091]]]), array([[[-0.31647239, -0.29929659, -0.31647134, -0.31632813]]])]\n",
      "21\n",
      "29\n",
      "[[-0.31647237 -0.29684888 -0.31647126 -0.31631457]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.7393e-04 - mse: 1.7393e-04\n",
      "[[[-0.31544188 -0.3073387  -0.30595952 -0.2993237 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647252, -0.30954841, -0.31647179, -0.316394  ]]]), array([[[-0.3164725 , -0.30829433, -0.31647172, -0.31638475]]]), array([[[-0.31647248, -0.30687709, -0.31647165, -0.31637485]]]), array([[[-0.31647246, -0.30528309, -0.31647157, -0.31636425]]]), array([[[-0.31647244, -0.30349821, -0.3164715 , -0.31635295]]]), array([[[-0.31647241, -0.30150778, -0.31647142, -0.31634091]]]), array([[[-0.31647239, -0.29929659, -0.31647134, -0.31632813]]]), array([[[-0.31647237, -0.29684888, -0.31647126, -0.31631457]]])]\n",
      "22\n",
      "30\n",
      "[[-0.31647235 -0.29414836 -0.31647118 -0.31630023]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 1.4486e-04 - mse: 1.4486e-04\n",
      "[[[-0.31458494 -0.30540982 -0.30763012 -0.30146664]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164725 , -0.30829433, -0.31647172, -0.31638475]]]), array([[[-0.31647248, -0.30687709, -0.31647165, -0.31637485]]]), array([[[-0.31647246, -0.30528309, -0.31647157, -0.31636425]]]), array([[[-0.31647244, -0.30349821, -0.3164715 , -0.31635295]]]), array([[[-0.31647241, -0.30150778, -0.31647142, -0.31634091]]]), array([[[-0.31647239, -0.29929659, -0.31647134, -0.31632813]]]), array([[[-0.31647237, -0.29684888, -0.31647126, -0.31631457]]]), array([[[-0.31647235, -0.29414836, -0.31647118, -0.31630023]]])]\n",
      "23\n",
      "31\n",
      "[[-0.31647233 -0.29117819 -0.31647109 -0.31628507]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.2686e-04 - mse: 1.2686e-04\n",
      "[[[-0.314085   -0.30328184 -0.30913833 -0.30323854]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647248, -0.30687709, -0.31647165, -0.31637485]]]), array([[[-0.31647246, -0.30528309, -0.31647157, -0.31636425]]]), array([[[-0.31647244, -0.30349821, -0.3164715 , -0.31635295]]]), array([[[-0.31647241, -0.30150778, -0.31647142, -0.31634091]]]), array([[[-0.31647239, -0.29929659, -0.31647134, -0.31632813]]]), array([[[-0.31647237, -0.29684888, -0.31647126, -0.31631457]]]), array([[[-0.31647235, -0.29414836, -0.31647118, -0.31630023]]]), array([[[-0.31647233, -0.29117819, -0.31647109, -0.31628507]]])]\n",
      "24\n",
      "32\n",
      "[[-0.31647231 -0.28792097 -0.31647101 -0.31626909]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.1829e-04 - mse: 1.1829e-04\n",
      "[[[-0.31349316 -0.30089962 -0.31032342 -0.30468157]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647246, -0.30528309, -0.31647157, -0.31636425]]]), array([[[-0.31647244, -0.30349821, -0.3164715 , -0.31635295]]]), array([[[-0.31647241, -0.30150778, -0.31647142, -0.31634091]]]), array([[[-0.31647239, -0.29929659, -0.31647134, -0.31632813]]]), array([[[-0.31647237, -0.29684888, -0.31647126, -0.31631457]]]), array([[[-0.31647235, -0.29414836, -0.31647118, -0.31630023]]]), array([[[-0.31647233, -0.29117819, -0.31647109, -0.31628507]]]), array([[[-0.31647231, -0.28792097, -0.31647101, -0.31626909]]])]\n",
      "25\n",
      "33\n",
      "[[-0.31647228 -0.28435879 -0.31647093 -0.31625225]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 1.1504e-04 - mse: 1.1504e-04\n",
      "[[[-0.31297457 -0.29828128 -0.31131965 -0.30583715]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647244, -0.30349821, -0.3164715 , -0.31635295]]]), array([[[-0.31647241, -0.30150778, -0.31647142, -0.31634091]]]), array([[[-0.31647239, -0.29929659, -0.31647134, -0.31632813]]]), array([[[-0.31647237, -0.29684888, -0.31647126, -0.31631457]]]), array([[[-0.31647235, -0.29414836, -0.31647118, -0.31630023]]]), array([[[-0.31647233, -0.29117819, -0.31647109, -0.31628507]]]), array([[[-0.31647231, -0.28792097, -0.31647101, -0.31626909]]]), array([[[-0.31647228, -0.28435879, -0.31647093, -0.31625225]]])]\n",
      "26\n",
      "34\n",
      "[[-0.31647226 -0.28047317 -0.31647084 -0.31623454]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.1717e-04 - mse: 1.1717e-04\n",
      "[[[-0.31252068 -0.29541898 -0.31216592 -0.30674443]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647241, -0.30150778, -0.31647142, -0.31634091]]]), array([[[-0.31647239, -0.29929659, -0.31647134, -0.31632813]]]), array([[[-0.31647237, -0.29684888, -0.31647126, -0.31631457]]]), array([[[-0.31647235, -0.29414836, -0.31647118, -0.31630023]]]), array([[[-0.31647233, -0.29117819, -0.31647109, -0.31628507]]]), array([[[-0.31647231, -0.28792097, -0.31647101, -0.31626909]]]), array([[[-0.31647228, -0.28435879, -0.31647093, -0.31625225]]]), array([[[-0.31647226, -0.28047317, -0.31647084, -0.31623454]]])]\n",
      "27\n",
      "35\n",
      "[[-0.31647224 -0.27624509 -0.31647076 -0.31621594]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.2392e-04 - mse: 1.2392e-04\n",
      "[[[-0.3121172  -0.29230198 -0.31289017 -0.30744046]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647239, -0.29929659, -0.31647134, -0.31632813]]]), array([[[-0.31647237, -0.29684888, -0.31647126, -0.31631457]]]), array([[[-0.31647235, -0.29414836, -0.31647118, -0.31630023]]]), array([[[-0.31647233, -0.29117819, -0.31647109, -0.31628507]]]), array([[[-0.31647231, -0.28792097, -0.31647101, -0.31626909]]]), array([[[-0.31647228, -0.28435879, -0.31647093, -0.31625225]]]), array([[[-0.31647226, -0.28047317, -0.31647084, -0.31623454]]]), array([[[-0.31647224, -0.27624509, -0.31647076, -0.31621594]]])]\n",
      "28\n",
      "36\n",
      "[[-0.31647222 -0.271655   -0.31647067 -0.31619644]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.3482e-04 - mse: 1.3482e-04\n",
      "[[[-0.31174818 -0.2889178  -0.3135128  -0.3079592 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647237, -0.29684888, -0.31647126, -0.31631457]]]), array([[[-0.31647235, -0.29414836, -0.31647118, -0.31630023]]]), array([[[-0.31647233, -0.29117819, -0.31647109, -0.31628507]]]), array([[[-0.31647231, -0.28792097, -0.31647101, -0.31626909]]]), array([[[-0.31647228, -0.28435879, -0.31647093, -0.31625225]]]), array([[[-0.31647226, -0.28047317, -0.31647084, -0.31623454]]]), array([[[-0.31647224, -0.27624509, -0.31647076, -0.31621594]]]), array([[[-0.31647222, -0.271655  , -0.31647067, -0.31619644]]])]\n",
      "29\n",
      "37\n",
      "[[-0.3164722  -0.26668279 -0.31647058 -0.316176  ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.4963e-04 - mse: 1.4963e-04\n",
      "[[[-0.31139156 -0.28524774 -0.31404647 -0.30830446]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647235, -0.29414836, -0.31647118, -0.31630023]]]), array([[[-0.31647233, -0.29117819, -0.31647109, -0.31628507]]]), array([[[-0.31647231, -0.28792097, -0.31647101, -0.31626909]]]), array([[[-0.31647228, -0.28435879, -0.31647093, -0.31625225]]]), array([[[-0.31647226, -0.28047317, -0.31647084, -0.31623454]]]), array([[[-0.31647224, -0.27624509, -0.31647076, -0.31621594]]]), array([[[-0.31647222, -0.271655  , -0.31647067, -0.31619644]]]), array([[[-0.3164722 , -0.26668279, -0.31647058, -0.316176  ]]])]\n",
      "30\n",
      "38\n",
      "[[-0.31647217 -0.26130783 -0.31647049 -0.31615461]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.6831e-04 - mse: 1.6831e-04\n",
      "[[[-0.31100124 -0.28125626 -0.31448972 -0.3083822 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647233, -0.29117819, -0.31647109, -0.31628507]]]), array([[[-0.31647231, -0.28792097, -0.31647101, -0.31626909]]]), array([[[-0.31647228, -0.28435879, -0.31647093, -0.31625225]]]), array([[[-0.31647226, -0.28047317, -0.31647084, -0.31623454]]]), array([[[-0.31647224, -0.27624509, -0.31647076, -0.31621594]]]), array([[[-0.31647222, -0.271655  , -0.31647067, -0.31619644]]]), array([[[-0.3164722 , -0.26668279, -0.31647058, -0.316176  ]]]), array([[[-0.31647217, -0.26130783, -0.31647049, -0.31615461]]])]\n",
      "31\n",
      "39\n",
      "[[-0.31647215 -0.25550892 -0.3164704  -0.31613226]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.9098e-04 - mse: 1.9098e-04\n",
      "[[[-0.31059566 -0.2769444  -0.31486505 -0.30831444]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647231, -0.28792097, -0.31647101, -0.31626909]]]), array([[[-0.31647228, -0.28435879, -0.31647093, -0.31625225]]]), array([[[-0.31647226, -0.28047317, -0.31647084, -0.31623454]]]), array([[[-0.31647224, -0.27624509, -0.31647076, -0.31621594]]]), array([[[-0.31647222, -0.271655  , -0.31647067, -0.31619644]]]), array([[[-0.3164722 , -0.26668279, -0.31647058, -0.316176  ]]]), array([[[-0.31647217, -0.26130783, -0.31647049, -0.31615461]]]), array([[[-0.31647215, -0.25550892, -0.3164704 , -0.31613226]]])]\n",
      "32\n",
      "40\n",
      "[[-0.31647213 -0.24926433 -0.31647031 -0.31610892]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.1791e-04 - mse: 2.1791e-04\n",
      "[[[-0.31016827 -0.27229595 -0.3151822  -0.3081221 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647228, -0.28435879, -0.31647093, -0.31625225]]]), array([[[-0.31647226, -0.28047317, -0.31647084, -0.31623454]]]), array([[[-0.31647224, -0.27624509, -0.31647076, -0.31621594]]]), array([[[-0.31647222, -0.271655  , -0.31647067, -0.31619644]]]), array([[[-0.3164722 , -0.26668279, -0.31647058, -0.316176  ]]]), array([[[-0.31647217, -0.26130783, -0.31647049, -0.31615461]]]), array([[[-0.31647215, -0.25550892, -0.3164704 , -0.31613226]]]), array([[[-0.31647213, -0.24926433, -0.31647031, -0.31610892]]])]\n",
      "33\n",
      "41\n",
      "[[-0.31647211 -0.24255179 -0.31647022 -0.31608457]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.4947e-04 - mse: 2.4947e-04\n",
      "[[[-0.30971426 -0.2672934  -0.31544992 -0.30782244]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647226, -0.28047317, -0.31647084, -0.31623454]]]), array([[[-0.31647224, -0.27624509, -0.31647076, -0.31621594]]]), array([[[-0.31647222, -0.271655  , -0.31647067, -0.31619644]]]), array([[[-0.3164722 , -0.26668279, -0.31647058, -0.316176  ]]]), array([[[-0.31647217, -0.26130783, -0.31647049, -0.31615461]]]), array([[[-0.31647215, -0.25550892, -0.3164704 , -0.31613226]]]), array([[[-0.31647213, -0.24926433, -0.31647031, -0.31610892]]]), array([[[-0.31647211, -0.24255179, -0.31647022, -0.31608457]]])]\n",
      "34\n",
      "42\n",
      "[[-0.31647209 -0.23534848 -0.31647012 -0.31605919]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 2.8617e-04 - mse: 2.8617e-04\n",
      "[[[-0.30925506 -0.26192614 -0.31566823 -0.30743858]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647224, -0.27624509, -0.31647076, -0.31621594]]]), array([[[-0.31647222, -0.271655  , -0.31647067, -0.31619644]]]), array([[[-0.3164722 , -0.26668279, -0.31647058, -0.316176  ]]]), array([[[-0.31647217, -0.26130783, -0.31647049, -0.31615461]]]), array([[[-0.31647215, -0.25550892, -0.3164704 , -0.31613226]]]), array([[[-0.31647213, -0.24926433, -0.31647031, -0.31610892]]]), array([[[-0.31647211, -0.24255179, -0.31647022, -0.31608457]]]), array([[[-0.31647209, -0.23534848, -0.31647012, -0.31605919]]])]\n",
      "35\n",
      "43\n",
      "[[-0.31647207 -0.22763103 -0.31647003 -0.31603277]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.2835e-04 - mse: 3.2835e-04\n",
      "[[[-0.3087621  -0.25616103 -0.3158374  -0.3069899 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647222, -0.271655  , -0.31647067, -0.31619644]]]), array([[[-0.3164722 , -0.26668279, -0.31647058, -0.316176  ]]]), array([[[-0.31647217, -0.26130783, -0.31647049, -0.31615461]]]), array([[[-0.31647215, -0.25550892, -0.3164704 , -0.31613226]]]), array([[[-0.31647213, -0.24926433, -0.31647031, -0.31610892]]]), array([[[-0.31647211, -0.24255179, -0.31647022, -0.31608457]]]), array([[[-0.31647209, -0.23534848, -0.31647012, -0.31605919]]]), array([[[-0.31647207, -0.22763103, -0.31647003, -0.31603277]]])]\n",
      "36\n",
      "44\n",
      "[[-0.31647204 -0.21937556 -0.31646994 -0.31600528]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.7518e-04 - mse: 3.7518e-04\n",
      "[[[-0.30805793 -0.24963838 -0.31614473 -0.30628127]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164722 , -0.26668279, -0.31647058, -0.316176  ]]]), array([[[-0.31647217, -0.26130783, -0.31647049, -0.31615461]]]), array([[[-0.31647215, -0.25550892, -0.3164704 , -0.31613226]]]), array([[[-0.31647213, -0.24926433, -0.31647031, -0.31610892]]]), array([[[-0.31647211, -0.24255179, -0.31647022, -0.31608457]]]), array([[[-0.31647209, -0.23534848, -0.31647012, -0.31605919]]]), array([[[-0.31647207, -0.22763103, -0.31647003, -0.31603277]]]), array([[[-0.31647204, -0.21937556, -0.31646994, -0.31600528]]])]\n",
      "37\n",
      "45\n",
      "[[-0.31647202 -0.2105576  -0.31646984 -0.31597672]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 4.2489e-04 - mse: 4.2489e-04\n",
      "[[[-0.30734682 -0.24266492 -0.3164462  -0.3054899 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647217, -0.26130783, -0.31647049, -0.31615461]]]), array([[[-0.31647215, -0.25550892, -0.3164704 , -0.31613226]]]), array([[[-0.31647213, -0.24926433, -0.31647031, -0.31610892]]]), array([[[-0.31647211, -0.24255179, -0.31647022, -0.31608457]]]), array([[[-0.31647209, -0.23534848, -0.31647012, -0.31605919]]]), array([[[-0.31647207, -0.22763103, -0.31647003, -0.31603277]]]), array([[[-0.31647204, -0.21937556, -0.31646994, -0.31600528]]]), array([[[-0.31647202, -0.2105576 , -0.31646984, -0.31597672]]])]\n",
      "38\n",
      "46\n",
      "[[-0.316472   -0.20115216 -0.31646974 -0.31594704]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 4.8133e-04 - mse: 4.8133e-04\n",
      "[[[-0.30664015 -0.23526028 -0.31672496 -0.30464777]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647215, -0.25550892, -0.3164704 , -0.31613226]]]), array([[[-0.31647213, -0.24926433, -0.31647031, -0.31610892]]]), array([[[-0.31647211, -0.24255179, -0.31647022, -0.31608457]]]), array([[[-0.31647209, -0.23534848, -0.31647012, -0.31605919]]]), array([[[-0.31647207, -0.22763103, -0.31647003, -0.31603277]]]), array([[[-0.31647204, -0.21937556, -0.31646994, -0.31600528]]]), array([[[-0.31647202, -0.2105576 , -0.31646984, -0.31597672]]]), array([[[-0.316472  , -0.20115216, -0.31646974, -0.31594704]]])]\n",
      "39\n",
      "47\n",
      "[[-0.31647198 -0.19113372 -0.31646965 -0.31591625]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 5.4567e-04 - mse: 5.4567e-04\n",
      "[[[-0.3059351  -0.22741336 -0.3169779  -0.30376762]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647213, -0.24926433, -0.31647031, -0.31610892]]]), array([[[-0.31647211, -0.24255179, -0.31647022, -0.31608457]]]), array([[[-0.31647209, -0.23534848, -0.31647012, -0.31605919]]]), array([[[-0.31647207, -0.22763103, -0.31647003, -0.31603277]]]), array([[[-0.31647204, -0.21937556, -0.31646994, -0.31600528]]]), array([[[-0.31647202, -0.2105576 , -0.31646984, -0.31597672]]]), array([[[-0.316472  , -0.20115216, -0.31646974, -0.31594704]]]), array([[[-0.31647198, -0.19113372, -0.31646965, -0.31591625]]])]\n",
      "40\n",
      "48\n",
      "[[-0.31647196 -0.18047619 -0.31646955 -0.31588432]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 6.1685e-04 - mse: 6.1685e-04\n",
      "[[[-0.3051821  -0.2189965  -0.31703007 -0.3027535 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647211, -0.24255179, -0.31647022, -0.31608457]]]), array([[[-0.31647209, -0.23534848, -0.31647012, -0.31605919]]]), array([[[-0.31647207, -0.22763103, -0.31647003, -0.31603277]]]), array([[[-0.31647204, -0.21937556, -0.31646994, -0.31600528]]]), array([[[-0.31647202, -0.2105576 , -0.31646984, -0.31597672]]]), array([[[-0.316472  , -0.20115216, -0.31646974, -0.31594704]]]), array([[[-0.31647198, -0.19113372, -0.31646965, -0.31591625]]]), array([[[-0.31647196, -0.18047619, -0.31646955, -0.31588432]]])]\n",
      "41\n",
      "49\n",
      "[[-0.31647194 -0.16915295 -0.31646945 -0.31585123]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 6.9708e-04 - mse: 6.9708e-04\n",
      "[[[-0.30441058 -0.21006075 -0.31699312 -0.3016598 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647209, -0.23534848, -0.31647012, -0.31605919]]]), array([[[-0.31647207, -0.22763103, -0.31647003, -0.31603277]]]), array([[[-0.31647204, -0.21937556, -0.31646994, -0.31600528]]]), array([[[-0.31647202, -0.2105576 , -0.31646984, -0.31597672]]]), array([[[-0.316472  , -0.20115216, -0.31646974, -0.31594704]]]), array([[[-0.31647198, -0.19113372, -0.31646965, -0.31591625]]]), array([[[-0.31647196, -0.18047619, -0.31646955, -0.31588432]]]), array([[[-0.31647194, -0.16915295, -0.31646945, -0.31585123]]])]\n",
      "42\n",
      "50\n",
      "[[-0.31647191 -0.15713685 -0.31646935 -0.31581696]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 7.8855e-04 - mse: 7.8855e-04\n",
      "[[[-0.30361658 -0.20061494 -0.3170151  -0.3004913 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647207, -0.22763103, -0.31647003, -0.31603277]]]), array([[[-0.31647204, -0.21937556, -0.31646994, -0.31600528]]]), array([[[-0.31647202, -0.2105576 , -0.31646984, -0.31597672]]]), array([[[-0.316472  , -0.20115216, -0.31646974, -0.31594704]]]), array([[[-0.31647198, -0.19113372, -0.31646965, -0.31591625]]]), array([[[-0.31647196, -0.18047619, -0.31646955, -0.31588432]]]), array([[[-0.31647194, -0.16915295, -0.31646945, -0.31585123]]]), array([[[-0.31647191, -0.15713685, -0.31646935, -0.31581696]]])]\n",
      "43\n",
      "51\n",
      "[[-0.31647189 -0.14440016 -0.31646925 -0.3157815 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 8.9239e-04 - mse: 8.9239e-04\n",
      "[[[-0.30279744 -0.19063224 -0.31708467 -0.29926032]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647204, -0.21937556, -0.31646994, -0.31600528]]]), array([[[-0.31647202, -0.2105576 , -0.31646984, -0.31597672]]]), array([[[-0.316472  , -0.20115216, -0.31646974, -0.31594704]]]), array([[[-0.31647198, -0.19113372, -0.31646965, -0.31591625]]]), array([[[-0.31647196, -0.18047619, -0.31646955, -0.31588432]]]), array([[[-0.31647194, -0.16915295, -0.31646945, -0.31585123]]]), array([[[-0.31647191, -0.15713685, -0.31646935, -0.31581696]]]), array([[[-0.31647189, -0.14440016, -0.31646925, -0.3157815 ]]])]\n",
      "44\n",
      "52\n",
      "[[-0.31647187 -0.13091465 -0.31646915 -0.31574482]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0010 - mse: 0.0010\n",
      "[[[-0.3019625  -0.18009606 -0.3171599  -0.29800063]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647202, -0.2105576 , -0.31646984, -0.31597672]]]), array([[[-0.316472  , -0.20115216, -0.31646974, -0.31594704]]]), array([[[-0.31647198, -0.19113372, -0.31646965, -0.31591625]]]), array([[[-0.31647196, -0.18047619, -0.31646955, -0.31588432]]]), array([[[-0.31647194, -0.16915295, -0.31646945, -0.31585123]]]), array([[[-0.31647191, -0.15713685, -0.31646935, -0.31581696]]]), array([[[-0.31647189, -0.14440016, -0.31646925, -0.3157815 ]]]), array([[[-0.31647187, -0.13091465, -0.31646915, -0.31574482]]])]\n",
      "45\n",
      "53\n",
      "[[-0.31647185 -0.11665152 -0.31646904 -0.3157069 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0011 - mse: 0.0011\n",
      "[[[-0.3007855  -0.16880424 -0.3169222  -0.29725718]]]\n",
      "-----------------------------\n",
      "[array([[[-0.316472  , -0.20115216, -0.31646974, -0.31594704]]]), array([[[-0.31647198, -0.19113372, -0.31646965, -0.31591625]]]), array([[[-0.31647196, -0.18047619, -0.31646955, -0.31588432]]]), array([[[-0.31647194, -0.16915295, -0.31646945, -0.31585123]]]), array([[[-0.31647191, -0.15713685, -0.31646935, -0.31581696]]]), array([[[-0.31647189, -0.14440016, -0.31646925, -0.3157815 ]]]), array([[[-0.31647187, -0.13091465, -0.31646915, -0.31574482]]]), array([[[-0.31647185, -0.11665152, -0.31646904, -0.3157069 ]]])]\n",
      "46\n",
      "54\n",
      "[[-0.31647183 -0.10158143 -0.31646894 -0.31566774]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0013 - mse: 0.0013\n",
      "[[[-0.29988942 -0.15733382 -0.31650078 -0.29673225]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647198, -0.19113372, -0.31646965, -0.31591625]]]), array([[[-0.31647196, -0.18047619, -0.31646955, -0.31588432]]]), array([[[-0.31647194, -0.16915295, -0.31646945, -0.31585123]]]), array([[[-0.31647191, -0.15713685, -0.31646935, -0.31581696]]]), array([[[-0.31647189, -0.14440016, -0.31646925, -0.3157815 ]]]), array([[[-0.31647187, -0.13091465, -0.31646915, -0.31574482]]]), array([[[-0.31647185, -0.11665152, -0.31646904, -0.3157069 ]]]), array([[[-0.31647183, -0.10158143, -0.31646894, -0.31566774]]])]\n",
      "47\n",
      "55\n",
      "[[-0.31647181 -0.0856745  -0.31646884 -0.31562731]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0015 - mse: 0.0015\n",
      "[[[-0.29927507 -0.1458239  -0.3155266  -0.29677773]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647196, -0.18047619, -0.31646955, -0.31588432]]]), array([[[-0.31647194, -0.16915295, -0.31646945, -0.31585123]]]), array([[[-0.31647191, -0.15713685, -0.31646935, -0.31581696]]]), array([[[-0.31647189, -0.14440016, -0.31646925, -0.3157815 ]]]), array([[[-0.31647187, -0.13091465, -0.31646915, -0.31574482]]]), array([[[-0.31647185, -0.11665152, -0.31646904, -0.3157069 ]]]), array([[[-0.31647183, -0.10158143, -0.31646894, -0.31566774]]]), array([[[-0.31647181, -0.0856745 , -0.31646884, -0.31562731]]])]\n",
      "48\n",
      "56\n",
      "[[-0.31647178 -0.0689003  -0.31646873 -0.31558558]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0017 - mse: 0.0017\n",
      "[[[-0.29867977 -0.1336445  -0.31487173 -0.29658952]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647194, -0.16915295, -0.31646945, -0.31585123]]]), array([[[-0.31647191, -0.15713685, -0.31646935, -0.31581696]]]), array([[[-0.31647189, -0.14440016, -0.31646925, -0.3157815 ]]]), array([[[-0.31647187, -0.13091465, -0.31646915, -0.31574482]]]), array([[[-0.31647185, -0.11665152, -0.31646904, -0.3157069 ]]]), array([[[-0.31647183, -0.10158143, -0.31646894, -0.31566774]]]), array([[[-0.31647181, -0.0856745 , -0.31646884, -0.31562731]]]), array([[[-0.31647178, -0.0689003 , -0.31646873, -0.31558558]]])]\n",
      "49\n",
      "57\n",
      "[[-0.31647176 -0.05122788 -0.31646863 -0.31554256]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0019 - mse: 0.0019\n",
      "[[[-0.29857075 -0.12030277 -0.3150886  -0.29489198]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647191, -0.15713685, -0.31646935, -0.31581696]]]), array([[[-0.31647189, -0.14440016, -0.31646925, -0.3157815 ]]]), array([[[-0.31647187, -0.13091465, -0.31646915, -0.31574482]]]), array([[[-0.31647185, -0.11665152, -0.31646904, -0.3157069 ]]]), array([[[-0.31647183, -0.10158143, -0.31646894, -0.31566774]]]), array([[[-0.31647181, -0.0856745 , -0.31646884, -0.31562731]]]), array([[[-0.31647178, -0.0689003 , -0.31646873, -0.31558558]]]), array([[[-0.31647176, -0.05122788, -0.31646863, -0.31554256]]])]\n",
      "50\n",
      "58\n",
      "[[-0.31647174 -0.03262572 -0.31646852 -0.3154982 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0022 - mse: 0.0022\n",
      "[[[-0.29746032 -0.10625238 -0.31482607 -0.2942726 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647189, -0.14440016, -0.31646925, -0.3157815 ]]]), array([[[-0.31647187, -0.13091465, -0.31646915, -0.31574482]]]), array([[[-0.31647185, -0.11665152, -0.31646904, -0.3157069 ]]]), array([[[-0.31647183, -0.10158143, -0.31646894, -0.31566774]]]), array([[[-0.31647181, -0.0856745 , -0.31646884, -0.31562731]]]), array([[[-0.31647178, -0.0689003 , -0.31646873, -0.31558558]]]), array([[[-0.31647176, -0.05122788, -0.31646863, -0.31554256]]]), array([[[-0.31647174, -0.03262572, -0.31646852, -0.3154982 ]]])]\n",
      "51\n",
      "59\n",
      "[[-0.31647172 -0.01306176 -0.31646841 -0.3154525 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0024 - mse: 0.0024\n",
      "[[[-0.29614285 -0.09124897 -0.3153509  -0.29330516]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647187, -0.13091465, -0.31646915, -0.31574482]]]), array([[[-0.31647185, -0.11665152, -0.31646904, -0.3157069 ]]]), array([[[-0.31647183, -0.10158143, -0.31646894, -0.31566774]]]), array([[[-0.31647181, -0.0856745 , -0.31646884, -0.31562731]]]), array([[[-0.31647178, -0.0689003 , -0.31646873, -0.31558558]]]), array([[[-0.31647176, -0.05122788, -0.31646863, -0.31554256]]]), array([[[-0.31647174, -0.03262572, -0.31646852, -0.3154982 ]]]), array([[[-0.31647172, -0.01306176, -0.31646841, -0.3154525 ]]])]\n",
      "52\n",
      "60\n",
      "[[-0.3164717   0.00749659 -0.31646831 -0.31540545]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0027 - mse: 0.0027\n",
      "[[[-0.29552403 -0.0752962  -0.31573972 -0.29206032]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647185, -0.11665152, -0.31646904, -0.3157069 ]]]), array([[[-0.31647183, -0.10158143, -0.31646894, -0.31566774]]]), array([[[-0.31647181, -0.0856745 , -0.31646884, -0.31562731]]]), array([[[-0.31647178, -0.0689003 , -0.31646873, -0.31558558]]]), array([[[-0.31647176, -0.05122788, -0.31646863, -0.31554256]]]), array([[[-0.31647174, -0.03262572, -0.31646852, -0.3154982 ]]]), array([[[-0.31647172, -0.01306176, -0.31646841, -0.3154525 ]]]), array([[[-0.3164717 ,  0.00749659, -0.31646831, -0.31540545]]])]\n",
      "53\n",
      "61\n",
      "[[-0.31647168  0.02908246 -0.3164682  -0.31535701]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0030 - mse: 0.0030\n",
      "[[[-0.29386717 -0.05862028 -0.31574893 -0.29164034]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647183, -0.10158143, -0.31646894, -0.31566774]]]), array([[[-0.31647181, -0.0856745 , -0.31646884, -0.31562731]]]), array([[[-0.31647178, -0.0689003 , -0.31646873, -0.31558558]]]), array([[[-0.31647176, -0.05122788, -0.31646863, -0.31554256]]]), array([[[-0.31647174, -0.03262572, -0.31646852, -0.3154982 ]]]), array([[[-0.31647172, -0.01306176, -0.31646841, -0.3154525 ]]]), array([[[-0.3164717 ,  0.00749659, -0.31646831, -0.31540545]]]), array([[[-0.31647168,  0.02908246, -0.3164682 , -0.31535701]]])]\n",
      "54\n",
      "62\n",
      "[[-0.31647165  0.05172956 -0.31646809 -0.31530718]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0033 - mse: 0.0033\n",
      "[[[-0.29325825 -0.04074707 -0.3169095  -0.2895829 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647181, -0.0856745 , -0.31646884, -0.31562731]]]), array([[[-0.31647178, -0.0689003 , -0.31646873, -0.31558558]]]), array([[[-0.31647176, -0.05122788, -0.31646863, -0.31554256]]]), array([[[-0.31647174, -0.03262572, -0.31646852, -0.3154982 ]]]), array([[[-0.31647172, -0.01306176, -0.31646841, -0.3154525 ]]]), array([[[-0.3164717 ,  0.00749659, -0.31646831, -0.31540545]]]), array([[[-0.31647168,  0.02908246, -0.3164682 , -0.31535701]]]), array([[[-0.31647165,  0.05172956, -0.31646809, -0.31530718]]])]\n",
      "55\n",
      "63\n",
      "[[-0.31647163  0.07547209 -0.31646798 -0.31525593]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0037 - mse: 0.0037\n",
      "[[[-0.29111058 -0.02235237 -0.31710887 -0.28936702]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647178, -0.0689003 , -0.31646873, -0.31558558]]]), array([[[-0.31647176, -0.05122788, -0.31646863, -0.31554256]]]), array([[[-0.31647174, -0.03262572, -0.31646852, -0.3154982 ]]]), array([[[-0.31647172, -0.01306176, -0.31646841, -0.3154525 ]]]), array([[[-0.3164717 ,  0.00749659, -0.31646831, -0.31540545]]]), array([[[-0.31647168,  0.02908246, -0.3164682 , -0.31535701]]]), array([[[-0.31647165,  0.05172956, -0.31646809, -0.31530718]]]), array([[[-0.31647163,  0.07547209, -0.31646798, -0.31525593]]])]\n",
      "56\n",
      "64\n",
      "[[-0.31647161  0.10034483 -0.31646787 -0.31520324]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0041 - mse: 0.0041\n",
      "[[[-0.29119742 -0.00288221 -0.3176392  -0.28822514]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647176, -0.05122788, -0.31646863, -0.31554256]]]), array([[[-0.31647174, -0.03262572, -0.31646852, -0.3154982 ]]]), array([[[-0.31647172, -0.01306176, -0.31646841, -0.3154525 ]]]), array([[[-0.3164717 ,  0.00749659, -0.31646831, -0.31540545]]]), array([[[-0.31647168,  0.02908246, -0.3164682 , -0.31535701]]]), array([[[-0.31647165,  0.05172956, -0.31646809, -0.31530718]]]), array([[[-0.31647163,  0.07547209, -0.31646798, -0.31525593]]]), array([[[-0.31647161,  0.10034483, -0.31646787, -0.31520324]]])]\n",
      "57\n",
      "65\n",
      "[[-0.31647159  0.1263831  -0.31646776 -0.31514911]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0046 - mse: 0.0046\n",
      "[[[-0.29051483  0.0171442  -0.3166334  -0.2876427 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647174, -0.03262572, -0.31646852, -0.3154982 ]]]), array([[[-0.31647172, -0.01306176, -0.31646841, -0.3154525 ]]]), array([[[-0.3164717 ,  0.00749659, -0.31646831, -0.31540545]]]), array([[[-0.31647168,  0.02908246, -0.3164682 , -0.31535701]]]), array([[[-0.31647165,  0.05172956, -0.31646809, -0.31530718]]]), array([[[-0.31647163,  0.07547209, -0.31646798, -0.31525593]]]), array([[[-0.31647161,  0.10034483, -0.31646787, -0.31520324]]]), array([[[-0.31647159,  0.1263831 , -0.31646776, -0.31514911]]])]\n",
      "58\n",
      "66\n",
      "[[-0.31647157  0.15362274 -0.31646765 -0.3150935 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0051 - mse: 0.0051\n",
      "[[[-0.29041252  0.038687   -0.31623048 -0.28587484]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647172, -0.01306176, -0.31646841, -0.3154525 ]]]), array([[[-0.3164717 ,  0.00749659, -0.31646831, -0.31540545]]]), array([[[-0.31647168,  0.02908246, -0.3164682 , -0.31535701]]]), array([[[-0.31647165,  0.05172956, -0.31646809, -0.31530718]]]), array([[[-0.31647163,  0.07547209, -0.31646798, -0.31525593]]]), array([[[-0.31647161,  0.10034483, -0.31646787, -0.31520324]]]), array([[[-0.31647159,  0.1263831 , -0.31646776, -0.31514911]]]), array([[[-0.31647157,  0.15362274, -0.31646765, -0.3150935 ]]])]\n",
      "59\n",
      "67\n",
      "[[-0.31647155  0.18210017 -0.31646753 -0.31503641]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0057 - mse: 0.0057\n",
      "[[[-0.29016766  0.06098578 -0.31542563 -0.28491434]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164717 ,  0.00749659, -0.31646831, -0.31540545]]]), array([[[-0.31647168,  0.02908246, -0.3164682 , -0.31535701]]]), array([[[-0.31647165,  0.05172956, -0.31646809, -0.31530718]]]), array([[[-0.31647163,  0.07547209, -0.31646798, -0.31525593]]]), array([[[-0.31647161,  0.10034483, -0.31646787, -0.31520324]]]), array([[[-0.31647159,  0.1263831 , -0.31646776, -0.31514911]]]), array([[[-0.31647157,  0.15362274, -0.31646765, -0.3150935 ]]]), array([[[-0.31647155,  0.18210017, -0.31646753, -0.31503641]]])]\n",
      "60\n",
      "68\n",
      "[[-0.31647152  0.21185231 -0.31646742 -0.31497782]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0061 - mse: 0.0061\n",
      "[[[-0.2897609   0.08529043 -0.31476426 -0.2841734 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647168,  0.02908246, -0.3164682 , -0.31535701]]]), array([[[-0.31647165,  0.05172956, -0.31646809, -0.31530718]]]), array([[[-0.31647163,  0.07547209, -0.31646798, -0.31525593]]]), array([[[-0.31647161,  0.10034483, -0.31646787, -0.31520324]]]), array([[[-0.31647159,  0.1263831 , -0.31646776, -0.31514911]]]), array([[[-0.31647157,  0.15362274, -0.31646765, -0.3150935 ]]]), array([[[-0.31647155,  0.18210017, -0.31646753, -0.31503641]]]), array([[[-0.31647152,  0.21185231, -0.31646742, -0.31497782]]])]\n",
      "61\n",
      "69\n",
      "[[-0.3164715   0.24291667 -0.31646731 -0.3149177 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0069 - mse: 0.0069\n",
      "[[[-0.28882304  0.10856516 -0.3133191  -0.28566763]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647165,  0.05172956, -0.31646809, -0.31530718]]]), array([[[-0.31647163,  0.07547209, -0.31646798, -0.31525593]]]), array([[[-0.31647161,  0.10034483, -0.31646787, -0.31520324]]]), array([[[-0.31647159,  0.1263831 , -0.31646776, -0.31514911]]]), array([[[-0.31647157,  0.15362274, -0.31646765, -0.3150935 ]]]), array([[[-0.31647155,  0.18210017, -0.31646753, -0.31503641]]]), array([[[-0.31647152,  0.21185231, -0.31646742, -0.31497782]]]), array([[[-0.3164715 ,  0.24291667, -0.31646731, -0.3149177 ]]])]\n",
      "62\n",
      "70\n",
      "[[-0.31647148  0.27533126 -0.31646719 -0.31485604]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0075 - mse: 0.0075\n",
      "[[[-0.29051888  0.13444293 -0.31418604 -0.28398016]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647163,  0.07547209, -0.31646798, -0.31525593]]]), array([[[-0.31647161,  0.10034483, -0.31646787, -0.31520324]]]), array([[[-0.31647159,  0.1263831 , -0.31646776, -0.31514911]]]), array([[[-0.31647157,  0.15362274, -0.31646765, -0.3150935 ]]]), array([[[-0.31647155,  0.18210017, -0.31646753, -0.31503641]]]), array([[[-0.31647152,  0.21185231, -0.31646742, -0.31497782]]]), array([[[-0.3164715 ,  0.24291667, -0.31646731, -0.3149177 ]]]), array([[[-0.31647148,  0.27533126, -0.31646719, -0.31485604]]])]\n",
      "63\n",
      "71\n",
      "[[-0.31647146  0.30913467 -0.31646708 -0.31479283]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0082 - mse: 0.0082\n",
      "[[[-0.29079828  0.16122937 -0.3125533  -0.28433174]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647161,  0.10034483, -0.31646787, -0.31520324]]]), array([[[-0.31647159,  0.1263831 , -0.31646776, -0.31514911]]]), array([[[-0.31647157,  0.15362274, -0.31646765, -0.3150935 ]]]), array([[[-0.31647155,  0.18210017, -0.31646753, -0.31503641]]]), array([[[-0.31647152,  0.21185231, -0.31646742, -0.31497782]]]), array([[[-0.3164715 ,  0.24291667, -0.31646731, -0.3149177 ]]]), array([[[-0.31647148,  0.27533126, -0.31646719, -0.31485604]]]), array([[[-0.31647146,  0.30913467, -0.31646708, -0.31479283]]])]\n",
      "64\n",
      "72\n",
      "[[-0.31647144  0.344366   -0.31646696 -0.31472804]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 0.0089 - mse: 0.0089\n",
      "[[[-0.29093122  0.19161464 -0.31389078 -0.2816431 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647159,  0.1263831 , -0.31646776, -0.31514911]]]), array([[[-0.31647157,  0.15362274, -0.31646765, -0.3150935 ]]]), array([[[-0.31647155,  0.18210017, -0.31646753, -0.31503641]]]), array([[[-0.31647152,  0.21185231, -0.31646742, -0.31497782]]]), array([[[-0.3164715 ,  0.24291667, -0.31646731, -0.3149177 ]]]), array([[[-0.31647148,  0.27533126, -0.31646719, -0.31485604]]]), array([[[-0.31647146,  0.30913467, -0.31646708, -0.31479283]]]), array([[[-0.31647144,  0.344366  , -0.31646696, -0.31472804]]])]\n",
      "65\n",
      "73\n",
      "[[-0.31647142  0.38106492 -0.31646684 -0.31466165]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0100 - mse: 0.0100\n",
      "[[[-0.29082298  0.2209528  -0.31272978 -0.28319353]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647157,  0.15362274, -0.31646765, -0.3150935 ]]]), array([[[-0.31647155,  0.18210017, -0.31646753, -0.31503641]]]), array([[[-0.31647152,  0.21185231, -0.31646742, -0.31497782]]]), array([[[-0.3164715 ,  0.24291667, -0.31646731, -0.3149177 ]]]), array([[[-0.31647148,  0.27533126, -0.31646719, -0.31485604]]]), array([[[-0.31647146,  0.30913467, -0.31646708, -0.31479283]]]), array([[[-0.31647144,  0.344366  , -0.31646696, -0.31472804]]]), array([[[-0.31647142,  0.38106492, -0.31646684, -0.31466165]]])]\n",
      "66\n",
      "74\n",
      "[[-0.31647139  0.41927163 -0.31646673 -0.31459366]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0103 - mse: 0.0103\n",
      "[[[-0.2915779   0.2563715  -0.31565097 -0.27947482]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647155,  0.18210017, -0.31646753, -0.31503641]]]), array([[[-0.31647152,  0.21185231, -0.31646742, -0.31497782]]]), array([[[-0.3164715 ,  0.24291667, -0.31646731, -0.3149177 ]]]), array([[[-0.31647148,  0.27533126, -0.31646719, -0.31485604]]]), array([[[-0.31647146,  0.30913467, -0.31646708, -0.31479283]]]), array([[[-0.31647144,  0.344366  , -0.31646696, -0.31472804]]]), array([[[-0.31647142,  0.38106492, -0.31646684, -0.31466165]]]), array([[[-0.31647139,  0.41927163, -0.31646673, -0.31459366]]])]\n",
      "67\n",
      "75\n",
      "[[-0.31647137  0.45902688 -0.31646661 -0.31452404]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0110 - mse: 0.0110\n",
      "[[[-0.29194266  0.290388   -0.31651974 -0.27993235]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647152,  0.21185231, -0.31646742, -0.31497782]]]), array([[[-0.3164715 ,  0.24291667, -0.31646731, -0.3149177 ]]]), array([[[-0.31647148,  0.27533126, -0.31646719, -0.31485604]]]), array([[[-0.31647146,  0.30913467, -0.31646708, -0.31479283]]]), array([[[-0.31647144,  0.344366  , -0.31646696, -0.31472804]]]), array([[[-0.31647142,  0.38106492, -0.31646684, -0.31466165]]]), array([[[-0.31647139,  0.41927163, -0.31646673, -0.31459366]]]), array([[[-0.31647137,  0.45902688, -0.31646661, -0.31452404]]])]\n",
      "68\n",
      "76\n",
      "[[-0.31647135  0.50037195 -0.31646649 -0.31445277]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0116 - mse: 0.0116\n",
      "[[[-0.29298472  0.32963735 -0.32005522 -0.27646443]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164715 ,  0.24291667, -0.31646731, -0.3149177 ]]]), array([[[-0.31647148,  0.27533126, -0.31646719, -0.31485604]]]), array([[[-0.31647146,  0.30913467, -0.31646708, -0.31479283]]]), array([[[-0.31647144,  0.344366  , -0.31646696, -0.31472804]]]), array([[[-0.31647142,  0.38106492, -0.31646684, -0.31466165]]]), array([[[-0.31647139,  0.41927163, -0.31646673, -0.31459366]]]), array([[[-0.31647137,  0.45902688, -0.31646661, -0.31452404]]]), array([[[-0.31647135,  0.50037195, -0.31646649, -0.31445277]]])]\n",
      "69\n",
      "77\n",
      "[[-0.31647133  0.54334868 -0.31646637 -0.31437984]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 0.0122 - mse: 0.0122\n",
      "[[[-0.29325473  0.3687116  -0.32279506 -0.27533722]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647148,  0.27533126, -0.31646719, -0.31485604]]]), array([[[-0.31647146,  0.30913467, -0.31646708, -0.31479283]]]), array([[[-0.31647144,  0.344366  , -0.31646696, -0.31472804]]]), array([[[-0.31647142,  0.38106492, -0.31646684, -0.31466165]]]), array([[[-0.31647139,  0.41927163, -0.31646673, -0.31459366]]]), array([[[-0.31647137,  0.45902688, -0.31646661, -0.31452404]]]), array([[[-0.31647135,  0.50037195, -0.31646649, -0.31445277]]]), array([[[-0.31647133,  0.54334868, -0.31646637, -0.31437984]]])]\n",
      "70\n",
      "78\n",
      "[[-0.31647131  0.58799944 -0.31646625 -0.31430522]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0129 - mse: 0.0129\n",
      "[[[-0.2951506   0.41132742 -0.3256455  -0.27132708]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647146,  0.30913467, -0.31646708, -0.31479283]]]), array([[[-0.31647144,  0.344366  , -0.31646696, -0.31472804]]]), array([[[-0.31647142,  0.38106492, -0.31646684, -0.31466165]]]), array([[[-0.31647139,  0.41927163, -0.31646673, -0.31459366]]]), array([[[-0.31647137,  0.45902688, -0.31646661, -0.31452404]]]), array([[[-0.31647135,  0.50037195, -0.31646649, -0.31445277]]]), array([[[-0.31647133,  0.54334868, -0.31646637, -0.31437984]]]), array([[[-0.31647131,  0.58799944, -0.31646625, -0.31430522]]])]\n",
      "71\n",
      "79\n",
      "[[-0.31647128  0.63436715 -0.31646613 -0.31422892]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0135 - mse: 0.0135\n",
      "[[[-0.29374084  0.4557572  -0.3255802  -0.27125746]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647144,  0.344366  , -0.31646696, -0.31472804]]]), array([[[-0.31647142,  0.38106492, -0.31646684, -0.31466165]]]), array([[[-0.31647139,  0.41927163, -0.31646673, -0.31459366]]]), array([[[-0.31647137,  0.45902688, -0.31646661, -0.31452404]]]), array([[[-0.31647135,  0.50037195, -0.31646649, -0.31445277]]]), array([[[-0.31647133,  0.54334868, -0.31646637, -0.31437984]]]), array([[[-0.31647131,  0.58799944, -0.31646625, -0.31430522]]]), array([[[-0.31647128,  0.63436715, -0.31646613, -0.31422892]]])]\n",
      "72\n",
      "80\n",
      "[[-0.31647126  0.68249527 -0.31646601 -0.31415089]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0137 - mse: 0.0137\n",
      "[[[-0.29515964  0.5055193  -0.32817656 -0.2672486 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647142,  0.38106492, -0.31646684, -0.31466165]]]), array([[[-0.31647139,  0.41927163, -0.31646673, -0.31459366]]]), array([[[-0.31647137,  0.45902688, -0.31646661, -0.31452404]]]), array([[[-0.31647135,  0.50037195, -0.31646649, -0.31445277]]]), array([[[-0.31647133,  0.54334868, -0.31646637, -0.31437984]]]), array([[[-0.31647131,  0.58799944, -0.31646625, -0.31430522]]]), array([[[-0.31647128,  0.63436715, -0.31646613, -0.31422892]]]), array([[[-0.31647126,  0.68249527, -0.31646601, -0.31415089]]])]\n",
      "73\n",
      "81\n",
      "[[-0.31647124  0.73242782 -0.31646589 -0.31407113]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0137 - mse: 0.0137\n",
      "[[[-0.29527992  0.55953026 -0.33227614 -0.26136488]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647139,  0.41927163, -0.31646673, -0.31459366]]]), array([[[-0.31647137,  0.45902688, -0.31646661, -0.31452404]]]), array([[[-0.31647135,  0.50037195, -0.31646649, -0.31445277]]]), array([[[-0.31647133,  0.54334868, -0.31646637, -0.31437984]]]), array([[[-0.31647131,  0.58799944, -0.31646625, -0.31430522]]]), array([[[-0.31647128,  0.63436715, -0.31646613, -0.31422892]]]), array([[[-0.31647126,  0.68249527, -0.31646601, -0.31415089]]]), array([[[-0.31647124,  0.73242782, -0.31646589, -0.31407113]]])]\n",
      "74\n",
      "82\n",
      "[[-0.31647122  0.78420934 -0.31646577 -0.31398963]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0135 - mse: 0.0135\n",
      "[[[-0.297484    0.6156672  -0.33300656 -0.260797  ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647137,  0.45902688, -0.31646661, -0.31452404]]]), array([[[-0.31647135,  0.50037195, -0.31646649, -0.31445277]]]), array([[[-0.31647133,  0.54334868, -0.31646637, -0.31437984]]]), array([[[-0.31647131,  0.58799944, -0.31646625, -0.31430522]]]), array([[[-0.31647128,  0.63436715, -0.31646613, -0.31422892]]]), array([[[-0.31647126,  0.68249527, -0.31646601, -0.31415089]]]), array([[[-0.31647124,  0.73242782, -0.31646589, -0.31407113]]]), array([[[-0.31647122,  0.78420934, -0.31646577, -0.31398963]]])]\n",
      "75\n",
      "83\n",
      "[[-0.3164712   0.83788491 -0.31646564 -0.31390635]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0130 - mse: 0.0130\n",
      "[[[-0.29846698  0.6775202  -0.335622   -0.25901103]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647135,  0.50037195, -0.31646649, -0.31445277]]]), array([[[-0.31647133,  0.54334868, -0.31646637, -0.31437984]]]), array([[[-0.31647131,  0.58799944, -0.31646625, -0.31430522]]]), array([[[-0.31647128,  0.63436715, -0.31646613, -0.31422892]]]), array([[[-0.31647126,  0.68249527, -0.31646601, -0.31415089]]]), array([[[-0.31647124,  0.73242782, -0.31646589, -0.31407113]]]), array([[[-0.31647122,  0.78420934, -0.31646577, -0.31398963]]]), array([[[-0.3164712 ,  0.83788491, -0.31646564, -0.31390635]]])]\n",
      "76\n",
      "84\n",
      "[[-0.31647118  0.89350019 -0.31646552 -0.3138213 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0123 - mse: 0.0123\n",
      "[[[-0.2998234   0.7402061  -0.33619058 -0.26016837]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647133,  0.54334868, -0.31646637, -0.31437984]]]), array([[[-0.31647131,  0.58799944, -0.31646625, -0.31430522]]]), array([[[-0.31647128,  0.63436715, -0.31646613, -0.31422892]]]), array([[[-0.31647126,  0.68249527, -0.31646601, -0.31415089]]]), array([[[-0.31647124,  0.73242782, -0.31646589, -0.31407113]]]), array([[[-0.31647122,  0.78420934, -0.31646577, -0.31398963]]]), array([[[-0.3164712 ,  0.83788491, -0.31646564, -0.31390635]]]), array([[[-0.31647118,  0.89350019, -0.31646552, -0.3138213 ]]])]\n",
      "77\n",
      "85\n",
      "[[-0.31647115  0.95110134 -0.3164654  -0.31373444]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 0.0117 - mse: 0.0117\n",
      "[[[-0.30076244  0.8090594  -0.33824846 -0.26020494]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647131,  0.58799944, -0.31646625, -0.31430522]]]), array([[[-0.31647128,  0.63436715, -0.31646613, -0.31422892]]]), array([[[-0.31647126,  0.68249527, -0.31646601, -0.31415089]]]), array([[[-0.31647124,  0.73242782, -0.31646589, -0.31407113]]]), array([[[-0.31647122,  0.78420934, -0.31646577, -0.31398963]]]), array([[[-0.3164712 ,  0.83788491, -0.31646564, -0.31390635]]]), array([[[-0.31647118,  0.89350019, -0.31646552, -0.3138213 ]]]), array([[[-0.31647115,  0.95110134, -0.3164654 , -0.31373444]]])]\n",
      "78\n",
      "86\n",
      "[[-0.31647113  1.01073508 -0.31646527 -0.31364576]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0106 - mse: 0.0106\n",
      "[[[-0.3009885   0.88027334 -0.3405602  -0.25875005]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647128,  0.63436715, -0.31646613, -0.31422892]]]), array([[[-0.31647126,  0.68249527, -0.31646601, -0.31415089]]]), array([[[-0.31647124,  0.73242782, -0.31646589, -0.31407113]]]), array([[[-0.31647122,  0.78420934, -0.31646577, -0.31398963]]]), array([[[-0.3164712 ,  0.83788491, -0.31646564, -0.31390635]]]), array([[[-0.31647118,  0.89350019, -0.31646552, -0.3138213 ]]]), array([[[-0.31647115,  0.95110134, -0.3164654 , -0.31373444]]]), array([[[-0.31647113,  1.01073508, -0.31646527, -0.31364576]]])]\n",
      "79\n",
      "87\n",
      "[[-0.31647111  1.07244869 -0.31646515 -0.31355525]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0099 - mse: 0.0099\n",
      "[[[-0.3055021   0.95384777 -0.33872682 -0.2649086 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647126,  0.68249527, -0.31646601, -0.31415089]]]), array([[[-0.31647124,  0.73242782, -0.31646589, -0.31407113]]]), array([[[-0.31647122,  0.78420934, -0.31646577, -0.31398963]]]), array([[[-0.3164712 ,  0.83788491, -0.31646564, -0.31390635]]]), array([[[-0.31647118,  0.89350019, -0.31646552, -0.3138213 ]]]), array([[[-0.31647115,  0.95110134, -0.3164654 , -0.31373444]]]), array([[[-0.31647113,  1.01073508, -0.31646527, -0.31364576]]]), array([[[-0.31647111,  1.07244869, -0.31646515, -0.31355525]]])]\n",
      "80\n",
      "88\n",
      "[[-0.31647109  1.13628997 -0.31646502 -0.31346288]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0087 - mse: 0.0087\n",
      "[[[-0.30661508  1.0291731  -0.33659738 -0.27000704]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647124,  0.73242782, -0.31646589, -0.31407113]]]), array([[[-0.31647122,  0.78420934, -0.31646577, -0.31398963]]]), array([[[-0.3164712 ,  0.83788491, -0.31646564, -0.31390635]]]), array([[[-0.31647118,  0.89350019, -0.31646552, -0.3138213 ]]]), array([[[-0.31647115,  0.95110134, -0.3164654 , -0.31373444]]]), array([[[-0.31647113,  1.01073508, -0.31646527, -0.31364576]]]), array([[[-0.31647111,  1.07244869, -0.31646515, -0.31355525]]]), array([[[-0.31647109,  1.13628997, -0.31646502, -0.31346288]]])]\n",
      "81\n",
      "89\n",
      "[[-0.31647107  1.20230728 -0.31646489 -0.31336865]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0075 - mse: 0.0075\n",
      "[[[-0.30671263  1.1111203  -0.336024   -0.27317497]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647122,  0.78420934, -0.31646577, -0.31398963]]]), array([[[-0.3164712 ,  0.83788491, -0.31646564, -0.31390635]]]), array([[[-0.31647118,  0.89350019, -0.31646552, -0.3138213 ]]]), array([[[-0.31647115,  0.95110134, -0.3164654 , -0.31373444]]]), array([[[-0.31647113,  1.01073508, -0.31646527, -0.31364576]]]), array([[[-0.31647111,  1.07244869, -0.31646515, -0.31355525]]]), array([[[-0.31647109,  1.13628997, -0.31646502, -0.31346288]]]), array([[[-0.31647107,  1.20230728, -0.31646489, -0.31336865]]])]\n",
      "82\n",
      "90\n",
      "[[-0.31647105  1.2705495  -0.31646477 -0.31327252]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0060 - mse: 0.0060\n",
      "[[[-0.30548748  1.1970632  -0.33682835 -0.27480865]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164712 ,  0.83788491, -0.31646564, -0.31390635]]]), array([[[-0.31647118,  0.89350019, -0.31646552, -0.3138213 ]]]), array([[[-0.31647115,  0.95110134, -0.3164654 , -0.31373444]]]), array([[[-0.31647113,  1.01073508, -0.31646527, -0.31364576]]]), array([[[-0.31647111,  1.07244869, -0.31646515, -0.31355525]]]), array([[[-0.31647109,  1.13628997, -0.31646502, -0.31346288]]]), array([[[-0.31647107,  1.20230728, -0.31646489, -0.31336865]]]), array([[[-0.31647105,  1.2705495 , -0.31646477, -0.31327252]]])]\n",
      "83\n",
      "91\n",
      "[[-0.31647102  1.34106608 -0.31646464 -0.3131745 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0047 - mse: 0.0047\n",
      "[[[-0.3085623   1.2856528  -0.33529478 -0.28086627]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647118,  0.89350019, -0.31646552, -0.3138213 ]]]), array([[[-0.31647115,  0.95110134, -0.3164654 , -0.31373444]]]), array([[[-0.31647113,  1.01073508, -0.31646527, -0.31364576]]]), array([[[-0.31647111,  1.07244869, -0.31646515, -0.31355525]]]), array([[[-0.31647109,  1.13628997, -0.31646502, -0.31346288]]]), array([[[-0.31647107,  1.20230728, -0.31646489, -0.31336865]]]), array([[[-0.31647105,  1.2705495 , -0.31646477, -0.31327252]]]), array([[[-0.31647102,  1.34106608, -0.31646464, -0.3131745 ]]])]\n",
      "84\n",
      "92\n",
      "[[-0.316471    1.413907   -0.31646451 -0.31307455]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0036 - mse: 0.0036\n",
      "[[[-0.3088984   1.3736552  -0.33412164 -0.2839612 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647115,  0.95110134, -0.3164654 , -0.31373444]]]), array([[[-0.31647113,  1.01073508, -0.31646527, -0.31364576]]]), array([[[-0.31647111,  1.07244869, -0.31646515, -0.31355525]]]), array([[[-0.31647109,  1.13628997, -0.31646502, -0.31346288]]]), array([[[-0.31647107,  1.20230728, -0.31646489, -0.31336865]]]), array([[[-0.31647105,  1.2705495 , -0.31646477, -0.31327252]]]), array([[[-0.31647102,  1.34106608, -0.31646464, -0.3131745 ]]]), array([[[-0.316471  ,  1.413907  , -0.31646451, -0.31307455]]])]\n",
      "85\n",
      "93\n",
      "[[-0.31647098  1.48912278 -0.31646438 -0.31297267]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0028 - mse: 0.0028\n",
      "[[[-0.31149217  1.4590294  -0.3314551  -0.28906834]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647113,  1.01073508, -0.31646527, -0.31364576]]]), array([[[-0.31647111,  1.07244869, -0.31646515, -0.31355525]]]), array([[[-0.31647109,  1.13628997, -0.31646502, -0.31346288]]]), array([[[-0.31647107,  1.20230728, -0.31646489, -0.31336865]]]), array([[[-0.31647105,  1.2705495 , -0.31646477, -0.31327252]]]), array([[[-0.31647102,  1.34106608, -0.31646464, -0.3131745 ]]]), array([[[-0.316471  ,  1.413907  , -0.31646451, -0.31307455]]]), array([[[-0.31647098,  1.48912278, -0.31646438, -0.31297267]]])]\n",
      "86\n",
      "94\n",
      "[[-0.31647096  1.5667645  -0.31646425 -0.31286883]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 22ms/sample - loss: 0.0021 - mse: 0.0021\n",
      "[[[-0.3149566  1.5473778 -0.3296122 -0.2925412]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647111,  1.07244869, -0.31646515, -0.31355525]]]), array([[[-0.31647109,  1.13628997, -0.31646502, -0.31346288]]]), array([[[-0.31647107,  1.20230728, -0.31646489, -0.31336865]]]), array([[[-0.31647105,  1.2705495 , -0.31646477, -0.31327252]]]), array([[[-0.31647102,  1.34106608, -0.31646464, -0.3131745 ]]]), array([[[-0.316471  ,  1.413907  , -0.31646451, -0.31307455]]]), array([[[-0.31647098,  1.48912278, -0.31646438, -0.31297267]]]), array([[[-0.31647096,  1.5667645 , -0.31646425, -0.31286883]]])]\n",
      "87\n",
      "95\n",
      "[[-0.31647094  1.64688375 -0.31646412 -0.31276302]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0016 - mse: 0.0016\n",
      "[[[-0.31692427  1.6347568  -0.32673746 -0.2963638 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647109,  1.13628997, -0.31646502, -0.31346288]]]), array([[[-0.31647107,  1.20230728, -0.31646489, -0.31336865]]]), array([[[-0.31647105,  1.2705495 , -0.31646477, -0.31327252]]]), array([[[-0.31647102,  1.34106608, -0.31646464, -0.3131745 ]]]), array([[[-0.316471  ,  1.413907  , -0.31646451, -0.31307455]]]), array([[[-0.31647098,  1.48912278, -0.31646438, -0.31297267]]]), array([[[-0.31647096,  1.5667645 , -0.31646425, -0.31286883]]]), array([[[-0.31647094,  1.64688375, -0.31646412, -0.31276302]]])]\n",
      "88\n",
      "96\n",
      "[[-0.31647092  1.72953271 -0.31646399 -0.31265522]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0013 - mse: 0.0013\n",
      "[[[-0.31368563  1.7254483  -0.32422495 -0.29866278]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647107,  1.20230728, -0.31646489, -0.31336865]]]), array([[[-0.31647105,  1.2705495 , -0.31646477, -0.31327252]]]), array([[[-0.31647102,  1.34106608, -0.31646464, -0.3131745 ]]]), array([[[-0.316471  ,  1.413907  , -0.31646451, -0.31307455]]]), array([[[-0.31647098,  1.48912278, -0.31646438, -0.31297267]]]), array([[[-0.31647096,  1.5667645 , -0.31646425, -0.31286883]]]), array([[[-0.31647094,  1.64688375, -0.31646412, -0.31276302]]]), array([[[-0.31647092,  1.72953271, -0.31646399, -0.31265522]]])]\n",
      "89\n",
      "97\n",
      "[[-0.31647089  1.81476406 -0.31646386 -0.31254542]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0010 - mse: 0.0010\n",
      "[[[-0.309509    1.8156441  -0.3191306  -0.30363593]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647105,  1.2705495 , -0.31646477, -0.31327252]]]), array([[[-0.31647102,  1.34106608, -0.31646464, -0.3131745 ]]]), array([[[-0.316471  ,  1.413907  , -0.31646451, -0.31307455]]]), array([[[-0.31647098,  1.48912278, -0.31646438, -0.31297267]]]), array([[[-0.31647096,  1.5667645 , -0.31646425, -0.31286883]]]), array([[[-0.31647094,  1.64688375, -0.31646412, -0.31276302]]]), array([[[-0.31647092,  1.72953271, -0.31646399, -0.31265522]]]), array([[[-0.31647089,  1.81476406, -0.31646386, -0.31254542]]])]\n",
      "90\n",
      "98\n",
      "[[-0.31647087  1.90263105 -0.31646373 -0.3124336 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 8.1471e-04 - mse: 8.1471e-04\n",
      "[[[-0.3042789   1.9087005  -0.31854212 -0.30517086]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647102,  1.34106608, -0.31646464, -0.3131745 ]]]), array([[[-0.316471  ,  1.413907  , -0.31646451, -0.31307455]]]), array([[[-0.31647098,  1.48912278, -0.31646438, -0.31297267]]]), array([[[-0.31647096,  1.5667645 , -0.31646425, -0.31286883]]]), array([[[-0.31647094,  1.64688375, -0.31646412, -0.31276302]]]), array([[[-0.31647092,  1.72953271, -0.31646399, -0.31265522]]]), array([[[-0.31647089,  1.81476406, -0.31646386, -0.31254542]]]), array([[[-0.31647087,  1.90263105, -0.31646373, -0.3124336 ]]])]\n",
      "91\n",
      "99\n",
      "[[-0.31647085  1.99318746 -0.3164636  -0.31231974]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 6.6728e-04 - mse: 6.6728e-04\n",
      "[[[-0.3047186   2.0062807  -0.31992194 -0.30671015]]]\n",
      "-----------------------------\n",
      "[array([[[-0.316471  ,  1.413907  , -0.31646451, -0.31307455]]]), array([[[-0.31647098,  1.48912278, -0.31646438, -0.31297267]]]), array([[[-0.31647096,  1.5667645 , -0.31646425, -0.31286883]]]), array([[[-0.31647094,  1.64688375, -0.31646412, -0.31276302]]]), array([[[-0.31647092,  1.72953271, -0.31646399, -0.31265522]]]), array([[[-0.31647089,  1.81476406, -0.31646386, -0.31254542]]]), array([[[-0.31647087,  1.90263105, -0.31646373, -0.3124336 ]]]), array([[[-0.31647085,  1.99318746, -0.3164636 , -0.31231974]]])]\n",
      "92\n",
      "100\n",
      "[[-0.31647083  2.08648763 -0.31646346 -0.31220382]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 4.0172e-04 - mse: 4.0172e-04\n",
      "[[[-0.30767238  2.1038272  -0.32148385 -0.30846855]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647098,  1.48912278, -0.31646438, -0.31297267]]]), array([[[-0.31647096,  1.5667645 , -0.31646425, -0.31286883]]]), array([[[-0.31647094,  1.64688375, -0.31646412, -0.31276302]]]), array([[[-0.31647092,  1.72953271, -0.31646399, -0.31265522]]]), array([[[-0.31647089,  1.81476406, -0.31646386, -0.31254542]]]), array([[[-0.31647087,  1.90263105, -0.31646373, -0.3124336 ]]]), array([[[-0.31647085,  1.99318746, -0.3164636 , -0.31231974]]]), array([[[-0.31647083,  2.08648763, -0.31646346, -0.31220382]]])]\n",
      "93\n",
      "101\n",
      "[[-0.31647081  2.18258641 -0.31646333 -0.31208583]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.6450e-04 - mse: 3.6450e-04\n",
      "[[[-0.3071064   2.2025337  -0.32194036 -0.30759993]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647096,  1.5667645 , -0.31646425, -0.31286883]]]), array([[[-0.31647094,  1.64688375, -0.31646412, -0.31276302]]]), array([[[-0.31647092,  1.72953271, -0.31646399, -0.31265522]]]), array([[[-0.31647089,  1.81476406, -0.31646386, -0.31254542]]]), array([[[-0.31647087,  1.90263105, -0.31646373, -0.3124336 ]]]), array([[[-0.31647085,  1.99318746, -0.3164636 , -0.31231974]]]), array([[[-0.31647083,  2.08648763, -0.31646346, -0.31220382]]]), array([[[-0.31647081,  2.18258641, -0.31646333, -0.31208583]]])]\n",
      "94\n",
      "102\n",
      "[[-0.31647079  2.28153923 -0.3164632  -0.31196575]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 3.5115e-04 - mse: 3.5115e-04\n",
      "[[[-0.3059717  2.303904  -0.3198492 -0.3068491]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647094,  1.64688375, -0.31646412, -0.31276302]]]), array([[[-0.31647092,  1.72953271, -0.31646399, -0.31265522]]]), array([[[-0.31647089,  1.81476406, -0.31646386, -0.31254542]]]), array([[[-0.31647087,  1.90263105, -0.31646373, -0.3124336 ]]]), array([[[-0.31647085,  1.99318746, -0.3164636 , -0.31231974]]]), array([[[-0.31647083,  2.08648763, -0.31646346, -0.31220382]]]), array([[[-0.31647081,  2.18258641, -0.31646333, -0.31208583]]]), array([[[-0.31647079,  2.28153923, -0.3164632 , -0.31196575]]])]\n",
      "95\n",
      "103\n",
      "[[-0.31647076  2.38340205 -0.31646306 -0.31184357]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 3.4326e-04 - mse: 3.4326e-04\n",
      "[[[-0.304895    2.4106448  -0.31841362 -0.30604175]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647092,  1.72953271, -0.31646399, -0.31265522]]]), array([[[-0.31647089,  1.81476406, -0.31646386, -0.31254542]]]), array([[[-0.31647087,  1.90263105, -0.31646373, -0.3124336 ]]]), array([[[-0.31647085,  1.99318746, -0.3164636 , -0.31231974]]]), array([[[-0.31647083,  2.08648763, -0.31646346, -0.31220382]]]), array([[[-0.31647081,  2.18258641, -0.31646333, -0.31208583]]]), array([[[-0.31647079,  2.28153923, -0.3164632 , -0.31196575]]]), array([[[-0.31647076,  2.38340205, -0.31646306, -0.31184357]]])]\n",
      "96\n",
      "104\n",
      "[[-0.31647074  2.48823136 -0.31646293 -0.31171926]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 3.1198e-04 - mse: 3.1198e-04\n",
      "[[[-0.30378836  2.5201018  -0.31948346 -0.3048873 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647089,  1.81476406, -0.31646386, -0.31254542]]]), array([[[-0.31647087,  1.90263105, -0.31646373, -0.3124336 ]]]), array([[[-0.31647085,  1.99318746, -0.3164636 , -0.31231974]]]), array([[[-0.31647083,  2.08648763, -0.31646346, -0.31220382]]]), array([[[-0.31647081,  2.18258641, -0.31646333, -0.31208583]]]), array([[[-0.31647079,  2.28153923, -0.3164632 , -0.31196575]]]), array([[[-0.31647076,  2.38340205, -0.31646306, -0.31184357]]]), array([[[-0.31647074,  2.48823136, -0.31646293, -0.31171926]]])]\n",
      "97\n",
      "105\n",
      "[[-0.31647072  2.5960842  -0.31646279 -0.31159282]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.6605e-04 - mse: 2.6605e-04\n",
      "[[[-0.30320278  2.6313264  -0.32101202 -0.3046012 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647087,  1.90263105, -0.31646373, -0.3124336 ]]]), array([[[-0.31647085,  1.99318746, -0.3164636 , -0.31231974]]]), array([[[-0.31647083,  2.08648763, -0.31646346, -0.31220382]]]), array([[[-0.31647081,  2.18258641, -0.31646333, -0.31208583]]]), array([[[-0.31647079,  2.28153923, -0.3164632 , -0.31196575]]]), array([[[-0.31647076,  2.38340205, -0.31646306, -0.31184357]]]), array([[[-0.31647074,  2.48823136, -0.31646293, -0.31171926]]]), array([[[-0.31647072,  2.5960842 , -0.31646279, -0.31159282]]])]\n",
      "98\n",
      "106\n",
      "[[-0.3164707   2.70701818 -0.31646266 -0.31146422]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 2.4317e-04 - mse: 2.4317e-04\n",
      "[[[-0.30270827  2.7454085  -0.32226023 -0.304846  ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647085,  1.99318746, -0.3164636 , -0.31231974]]]), array([[[-0.31647083,  2.08648763, -0.31646346, -0.31220382]]]), array([[[-0.31647081,  2.18258641, -0.31646333, -0.31208583]]]), array([[[-0.31647079,  2.28153923, -0.3164632 , -0.31196575]]]), array([[[-0.31647076,  2.38340205, -0.31646306, -0.31184357]]]), array([[[-0.31647074,  2.48823136, -0.31646293, -0.31171926]]]), array([[[-0.31647072,  2.5960842 , -0.31646279, -0.31159282]]]), array([[[-0.3164707 ,  2.70701818, -0.31646266, -0.31146422]]])]\n",
      "99\n",
      "107\n",
      "[[-0.31647068  2.82109141 -0.31646252 -0.31133345]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 2.2417e-04 - mse: 2.2417e-04\n",
      "[[[-0.3015996   2.8636088  -0.32250118 -0.30558094]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647083,  2.08648763, -0.31646346, -0.31220382]]]), array([[[-0.31647081,  2.18258641, -0.31646333, -0.31208583]]]), array([[[-0.31647079,  2.28153923, -0.3164632 , -0.31196575]]]), array([[[-0.31647076,  2.38340205, -0.31646306, -0.31184357]]]), array([[[-0.31647074,  2.48823136, -0.31646293, -0.31171926]]]), array([[[-0.31647072,  2.5960842 , -0.31646279, -0.31159282]]]), array([[[-0.3164707 ,  2.70701818, -0.31646266, -0.31146422]]]), array([[[-0.31647068,  2.82109141, -0.31646252, -0.31133345]]])]\n",
      "100\n",
      "108\n",
      "[[-0.31647066  2.93836258 -0.31646238 -0.31120049]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.8250e-04 - mse: 1.8250e-04\n",
      "[[[-0.30474174  2.9814107  -0.32363102 -0.30569693]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647081,  2.18258641, -0.31646333, -0.31208583]]]), array([[[-0.31647079,  2.28153923, -0.3164632 , -0.31196575]]]), array([[[-0.31647076,  2.38340205, -0.31646306, -0.31184357]]]), array([[[-0.31647074,  2.48823136, -0.31646293, -0.31171926]]]), array([[[-0.31647072,  2.5960842 , -0.31646279, -0.31159282]]]), array([[[-0.3164707 ,  2.70701818, -0.31646266, -0.31146422]]]), array([[[-0.31647068,  2.82109141, -0.31646252, -0.31133345]]]), array([[[-0.31647066,  2.93836258, -0.31646238, -0.31120049]]])]\n",
      "101\n",
      "109\n",
      "[[-0.31647063  3.0588909  -0.31646224 -0.31106533]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 2.0354e-04 - mse: 2.0354e-04\n",
      "[[[-0.3052555   3.106744   -0.32542008 -0.30470335]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647079,  2.28153923, -0.3164632 , -0.31196575]]]), array([[[-0.31647076,  2.38340205, -0.31646306, -0.31184357]]]), array([[[-0.31647074,  2.48823136, -0.31646293, -0.31171926]]]), array([[[-0.31647072,  2.5960842 , -0.31646279, -0.31159282]]]), array([[[-0.3164707 ,  2.70701818, -0.31646266, -0.31146422]]]), array([[[-0.31647068,  2.82109141, -0.31646252, -0.31133345]]]), array([[[-0.31647066,  2.93836258, -0.31646238, -0.31120049]]]), array([[[-0.31647063,  3.0588909 , -0.31646224, -0.31106533]]])]\n",
      "102\n",
      "110\n",
      "[[-0.31647061  3.18273612 -0.31646211 -0.31092795]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.6851e-04 - mse: 1.6851e-04\n",
      "[[[-0.30611217  3.2331405  -0.32596695 -0.30436623]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647076,  2.38340205, -0.31646306, -0.31184357]]]), array([[[-0.31647074,  2.48823136, -0.31646293, -0.31171926]]]), array([[[-0.31647072,  2.5960842 , -0.31646279, -0.31159282]]]), array([[[-0.3164707 ,  2.70701818, -0.31646266, -0.31146422]]]), array([[[-0.31647068,  2.82109141, -0.31646252, -0.31133345]]]), array([[[-0.31647066,  2.93836258, -0.31646238, -0.31120049]]]), array([[[-0.31647063,  3.0588909 , -0.31646224, -0.31106533]]]), array([[[-0.31647061,  3.18273612, -0.31646211, -0.31092795]]])]\n",
      "103\n",
      "111\n",
      "[[-0.31647059  3.30995856 -0.31646197 -0.31078832]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.6479e-04 - mse: 1.6479e-04\n",
      "[[[-0.30555084  3.3644674  -0.32626933 -0.3039221 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647074,  2.48823136, -0.31646293, -0.31171926]]]), array([[[-0.31647072,  2.5960842 , -0.31646279, -0.31159282]]]), array([[[-0.3164707 ,  2.70701818, -0.31646266, -0.31146422]]]), array([[[-0.31647068,  2.82109141, -0.31646252, -0.31133345]]]), array([[[-0.31647066,  2.93836258, -0.31646238, -0.31120049]]]), array([[[-0.31647063,  3.0588909 , -0.31646224, -0.31106533]]]), array([[[-0.31647061,  3.18273612, -0.31646211, -0.31092795]]]), array([[[-0.31647059,  3.30995856, -0.31646197, -0.31078832]]])]\n",
      "104\n",
      "112\n",
      "[[-0.31647057  3.44061906 -0.31646183 -0.31064645]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.3712e-04 - mse: 1.3712e-04\n",
      "[[[-0.30623826  3.4967062  -0.32639855 -0.30408254]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647072,  2.5960842 , -0.31646279, -0.31159282]]]), array([[[-0.3164707 ,  2.70701818, -0.31646266, -0.31146422]]]), array([[[-0.31647068,  2.82109141, -0.31646252, -0.31133345]]]), array([[[-0.31647066,  2.93836258, -0.31646238, -0.31120049]]]), array([[[-0.31647063,  3.0588909 , -0.31646224, -0.31106533]]]), array([[[-0.31647061,  3.18273612, -0.31646211, -0.31092795]]]), array([[[-0.31647059,  3.30995856, -0.31646197, -0.31078832]]]), array([[[-0.31647057,  3.44061906, -0.31646183, -0.31064645]]])]\n",
      "105\n",
      "113\n",
      "[[-0.31647055  3.57477902 -0.31646169 -0.3105023 ]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.5301e-04 - mse: 1.5301e-04\n",
      "[[[-0.30534005  3.636538   -0.3271222  -0.3036406 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164707 ,  2.70701818, -0.31646266, -0.31146422]]]), array([[[-0.31647068,  2.82109141, -0.31646252, -0.31133345]]]), array([[[-0.31647066,  2.93836258, -0.31646238, -0.31120049]]]), array([[[-0.31647063,  3.0588909 , -0.31646224, -0.31106533]]]), array([[[-0.31647061,  3.18273612, -0.31646211, -0.31092795]]]), array([[[-0.31647059,  3.30995856, -0.31646197, -0.31078832]]]), array([[[-0.31647057,  3.44061906, -0.31646183, -0.31064645]]]), array([[[-0.31647055,  3.57477902, -0.31646169, -0.3105023 ]]])]\n",
      "106\n",
      "114\n",
      "[[-0.31647052  3.71250036 -0.31646155 -0.31035587]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 1.2383e-04 - mse: 1.2383e-04\n",
      "[[[-0.3069756   3.7751575  -0.3270601  -0.30405363]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647068,  2.82109141, -0.31646252, -0.31133345]]]), array([[[-0.31647066,  2.93836258, -0.31646238, -0.31120049]]]), array([[[-0.31647063,  3.0588909 , -0.31646224, -0.31106533]]]), array([[[-0.31647061,  3.18273612, -0.31646211, -0.31092795]]]), array([[[-0.31647059,  3.30995856, -0.31646197, -0.31078832]]]), array([[[-0.31647057,  3.44061906, -0.31646183, -0.31064645]]]), array([[[-0.31647055,  3.57477902, -0.31646169, -0.3105023 ]]]), array([[[-0.31647052,  3.71250036, -0.31646155, -0.31035587]]])]\n",
      "107\n",
      "115\n",
      "[[-0.3164705   3.85384556 -0.31646141 -0.31020714]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 17ms/sample - loss: 1.4814e-04 - mse: 1.4814e-04\n",
      "[[[-0.30439964  3.9245229  -0.32758737 -0.30347642]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647066,  2.93836258, -0.31646238, -0.31120049]]]), array([[[-0.31647063,  3.0588909 , -0.31646224, -0.31106533]]]), array([[[-0.31647061,  3.18273612, -0.31646211, -0.31092795]]]), array([[[-0.31647059,  3.30995856, -0.31646197, -0.31078832]]]), array([[[-0.31647057,  3.44061906, -0.31646183, -0.31064645]]]), array([[[-0.31647055,  3.57477902, -0.31646169, -0.3105023 ]]]), array([[[-0.31647052,  3.71250036, -0.31646155, -0.31035587]]]), array([[[-0.3164705 ,  3.85384556, -0.31646141, -0.31020714]]])]\n",
      "108\n",
      "116\n",
      "[[-0.31647048  3.99887765 -0.31646127 -0.31005608]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 8.8653e-05 - mse: 8.8653e-05\n",
      "[[[-0.30690476  4.0648036  -0.3259257  -0.30517867]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647063,  3.0588909 , -0.31646224, -0.31106533]]]), array([[[-0.31647061,  3.18273612, -0.31646211, -0.31092795]]]), array([[[-0.31647059,  3.30995856, -0.31646197, -0.31078832]]]), array([[[-0.31647057,  3.44061906, -0.31646183, -0.31064645]]]), array([[[-0.31647055,  3.57477902, -0.31646169, -0.3105023 ]]]), array([[[-0.31647052,  3.71250036, -0.31646155, -0.31035587]]]), array([[[-0.3164705 ,  3.85384556, -0.31646141, -0.31020714]]]), array([[[-0.31647048,  3.99887765, -0.31646127, -0.31005608]]])]\n",
      "109\n",
      "117\n",
      "[[-0.31647046  4.14766019 -0.31646112 -0.30990269]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 1.8254e-04 - mse: 1.8254e-04\n",
      "[[[-0.2999683   4.2339716  -0.3288275  -0.30246788]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647061,  3.18273612, -0.31646211, -0.31092795]]]), array([[[-0.31647059,  3.30995856, -0.31646197, -0.31078832]]]), array([[[-0.31647057,  3.44061906, -0.31646183, -0.31064645]]]), array([[[-0.31647055,  3.57477902, -0.31646169, -0.3105023 ]]]), array([[[-0.31647052,  3.71250036, -0.31646155, -0.31035587]]]), array([[[-0.3164705 ,  3.85384556, -0.31646141, -0.31020714]]]), array([[[-0.31647048,  3.99887765, -0.31646127, -0.31005608]]]), array([[[-0.31647046,  4.14766019, -0.31646112, -0.30990269]]])]\n",
      "110\n",
      "118\n",
      "[[-0.31647044  4.30025728 -0.31646098 -0.30974695]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 4.2839e-05 - mse: 4.2839e-05\n",
      "[[[-0.31623012  4.355576   -0.3236978  -0.30839497]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647059,  3.30995856, -0.31646197, -0.31078832]]]), array([[[-0.31647057,  3.44061906, -0.31646183, -0.31064645]]]), array([[[-0.31647055,  3.57477902, -0.31646169, -0.3105023 ]]]), array([[[-0.31647052,  3.71250036, -0.31646155, -0.31035587]]]), array([[[-0.3164705 ,  3.85384556, -0.31646141, -0.31020714]]]), array([[[-0.31647048,  3.99887765, -0.31646127, -0.31005608]]]), array([[[-0.31647046,  4.14766019, -0.31646112, -0.30990269]]]), array([[[-0.31647044,  4.30025728, -0.31646098, -0.30974695]]])]\n",
      "111\n",
      "119\n",
      "[[-0.31647042  4.45673357 -0.31646084 -0.30958884]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 5.4422e-04 - mse: 5.4422e-04\n",
      "[[[-0.27750817  4.6009073  -0.33571935 -0.29454035]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647057,  3.44061906, -0.31646183, -0.31064645]]]), array([[[-0.31647055,  3.57477902, -0.31646169, -0.3105023 ]]]), array([[[-0.31647052,  3.71250036, -0.31646155, -0.31035587]]]), array([[[-0.3164705 ,  3.85384556, -0.31646141, -0.31020714]]]), array([[[-0.31647048,  3.99887765, -0.31646127, -0.31005608]]]), array([[[-0.31647046,  4.14766019, -0.31646112, -0.30990269]]]), array([[[-0.31647044,  4.30025728, -0.31646098, -0.30974695]]]), array([[[-0.31647042,  4.45673357, -0.31646084, -0.30958884]]])]\n",
      "112\n",
      "120\n",
      "[[-0.31647039  4.61715426 -0.3164607  -0.30942834]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 7.0192e-04 - mse: 7.0192e-04\n",
      "[[[-0.37853354  4.5440636  -0.3040645  -0.33044195]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647055,  3.57477902, -0.31646169, -0.3105023 ]]]), array([[[-0.31647052,  3.71250036, -0.31646155, -0.31035587]]]), array([[[-0.3164705 ,  3.85384556, -0.31646141, -0.31020714]]]), array([[[-0.31647048,  3.99887765, -0.31646127, -0.31005608]]]), array([[[-0.31647046,  4.14766019, -0.31646112, -0.30990269]]]), array([[[-0.31647044,  4.30025728, -0.31646098, -0.30974695]]]), array([[[-0.31647042,  4.45673357, -0.31646084, -0.30958884]]]), array([[[-0.31647039,  4.61715426, -0.3164607 , -0.30942834]]])]\n",
      "113\n",
      "121\n",
      "[[-0.31647037  4.78158509 -0.31646055 -0.30926544]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 16ms/sample - loss: 0.0099 - mse: 0.0099\n",
      "[[[-0.09976038  5.3711677  -0.41447824 -0.20976257]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647052,  3.71250036, -0.31646155, -0.31035587]]]), array([[[-0.3164705 ,  3.85384556, -0.31646141, -0.31020714]]]), array([[[-0.31647048,  3.99887765, -0.31646127, -0.31005608]]]), array([[[-0.31647046,  4.14766019, -0.31646112, -0.30990269]]]), array([[[-0.31647044,  4.30025728, -0.31646098, -0.30974695]]]), array([[[-0.31647042,  4.45673357, -0.31646084, -0.30958884]]]), array([[[-0.31647039,  4.61715426, -0.3164607 , -0.30942834]]]), array([[[-0.31647037,  4.78158509, -0.31646055, -0.30926544]]])]\n",
      "114\n",
      "122\n",
      "[[-0.31647035  4.95009233 -0.31646041 -0.30910013]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 0.0770 - mse: 0.0770\n",
      "[[[-0.9267171   3.4469717  -0.02418219 -0.5519113 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.3164705 ,  3.85384556, -0.31646141, -0.31020714]]]), array([[[-0.31647048,  3.99887765, -0.31646127, -0.31005608]]]), array([[[-0.31647046,  4.14766019, -0.31646112, -0.30990269]]]), array([[[-0.31647044,  4.30025728, -0.31646098, -0.30974695]]]), array([[[-0.31647042,  4.45673357, -0.31646084, -0.30958884]]]), array([[[-0.31647039,  4.61715426, -0.3164607 , -0.30942834]]]), array([[[-0.31647037,  4.78158509, -0.31646055, -0.30926544]]]), array([[[-0.31647035,  4.95009233, -0.31646041, -0.30910013]]])]\n",
      "115\n",
      "123\n",
      "[[-0.31647033  5.12274281 -0.31646026 -0.30893238]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 18ms/sample - loss: 0.8083 - mse: 0.8083\n",
      "[[[ 1.2029407   8.719729   -0.937331    0.33023018]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647048,  3.99887765, -0.31646127, -0.31005608]]]), array([[[-0.31647046,  4.14766019, -0.31646112, -0.30990269]]]), array([[[-0.31647044,  4.30025728, -0.31646098, -0.30974695]]]), array([[[-0.31647042,  4.45673357, -0.31646084, -0.30958884]]]), array([[[-0.31647039,  4.61715426, -0.3164607 , -0.30942834]]]), array([[[-0.31647037,  4.78158509, -0.31646055, -0.30926544]]]), array([[[-0.31647035,  4.95009233, -0.31646041, -0.30910013]]]), array([[[-0.31647033,  5.12274281, -0.31646026, -0.30893238]]])]\n",
      "116\n",
      "124\n",
      "[[-0.31647031  5.2996039  -0.31646012 -0.30876219]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 3.9148 - mse: 3.9148\n",
      "[[[-1.4429806  -0.42620015 -0.02709751 -0.8038543 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647046,  4.14766019, -0.31646112, -0.30990269]]]), array([[[-0.31647044,  4.30025728, -0.31646098, -0.30974695]]]), array([[[-0.31647042,  4.45673357, -0.31646084, -0.30958884]]]), array([[[-0.31647039,  4.61715426, -0.3164607 , -0.30942834]]]), array([[[-0.31647037,  4.78158509, -0.31646055, -0.30926544]]]), array([[[-0.31647035,  4.95009233, -0.31646041, -0.30910013]]]), array([[[-0.31647033,  5.12274281, -0.31646026, -0.30893238]]]), array([[[-0.31647031,  5.2996039 , -0.31646012, -0.30876219]]])]\n",
      "117\n",
      "125\n",
      "[[-0.31647029  5.4807435  -0.31645997 -0.30858953]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 9.1695 - mse: 9.1695\n",
      "[[[-0.36101085  0.7464149   0.0198632  -0.4471411 ]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647044,  4.30025728, -0.31646098, -0.30974695]]]), array([[[-0.31647042,  4.45673357, -0.31646084, -0.30958884]]]), array([[[-0.31647039,  4.61715426, -0.3164607 , -0.30942834]]]), array([[[-0.31647037,  4.78158509, -0.31646055, -0.30926544]]]), array([[[-0.31647035,  4.95009233, -0.31646041, -0.30910013]]]), array([[[-0.31647033,  5.12274281, -0.31646026, -0.30893238]]]), array([[[-0.31647031,  5.2996039 , -0.31646012, -0.30876219]]]), array([[[-0.31647029,  5.4807435 , -0.31645997, -0.30858953]]])]\n",
      "118\n",
      "126\n",
      "[[-0.31647026  5.66623007 -0.31645983 -0.30841438]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 6.0796 - mse: 6.0796\n",
      "[[[-0.5556347   1.377449    0.12681188 -0.52466315]]]\n",
      "-----------------------------\n",
      "[array([[[-0.31647042,  4.45673357, -0.31646084, -0.30958884]]]), array([[[-0.31647039,  4.61715426, -0.3164607 , -0.30942834]]]), array([[[-0.31647037,  4.78158509, -0.31646055, -0.30926544]]]), array([[[-0.31647035,  4.95009233, -0.31646041, -0.30910013]]]), array([[[-0.31647033,  5.12274281, -0.31646026, -0.30893238]]]), array([[[-0.31647031,  5.2996039 , -0.31646012, -0.30876219]]]), array([[[-0.31647029,  5.4807435 , -0.31645997, -0.30858953]]]), array([[[-0.31647026,  5.66623007, -0.31645983, -0.30841438]]])]\n",
      "119\n",
      "127\n",
      "[[-0.31647024  5.8561326  -0.31645968 -0.30823674]]\n",
      "Train on 1 samples\n",
      "1/1 [==============================] - 0s 15ms/sample - loss: 5.0717 - mse: 5.0717\n",
      "[[[-1.036915    3.1133575   0.33529696 -0.70209885]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_History = wavenet.train_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "juNy4Z3EgNo4",
    "outputId": "661acc26-4d70-45a9-814f-15fcaa65c30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38218366 -0.38218366 -0.38218366 -0.38218366 -0.38218366 -0.38218365\n",
      " -0.38218353 -0.3821828  -0.38217916 -0.38216348 -0.38210427 -0.38190359\n",
      " -0.38128342 -0.37951309 -0.37479657 -0.36296895 -0.33485486 -0.27113883\n",
      " -0.13277479  0.15634762  0.73979275  1.88041454  4.04659437]\n",
      "<class 'numpy.ndarray'>\n",
      "(23,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "G3PiGrYFjTE6",
    "outputId": "2eec6500-c721-4e1d-f112-9ce24e1cdbf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.38218366]]), array([[-0.38218365]]), array([[-0.38218353]]), array([[-0.3821828]]), array([[-0.38217916]]), array([[-0.38216348]]), array([[-0.38210427]]), array([[-0.38190359]])]\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAJw1KTYXcQn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KycLakrFe8gS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "WaveNet_Author.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
